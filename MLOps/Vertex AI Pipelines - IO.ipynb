{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30513be7",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps&file=Vertex+AI+Pipelines+-+IO.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Vertex%20AI%20Pipelines%20-%20IO.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FMLOps%2FVertex%2520AI%2520Pipelines%2520-%2520IO.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Vertex%20AI%20Pipelines%20-%20IO.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Vertex%20AI%20Pipelines%20-%20IO.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82b91d-bbec-4495-abf1-37a0d7f04342",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "This is part a [series of notebook based workflows](./readme.md) that teach all the ways to use pipelines and experiments within Vertex AI. The suggested order and description/reason is:\n",
    "\n",
    "||Notebook Workflow|Description|\n",
    "|---|---|---|\n",
    "||[Vertex AI Pipelines - Introduction](./Vertex%20AI%20Pipelines%20-%20Introduction.ipynb)|Introduction to pipelines with the console and Vertex AI SDK|\n",
    "||[Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)|An introduction to all the ways to create pipeline components from your code|\n",
    "|_**This Notebook**_|[Vertex AI Pipelines - IO](./Vertex%20AI%20Pipelines%20-%20IO.ipynb)|An overview of all the type of inputs and outputs for pipeline components|\n",
    "||[Vertex AI Pipelines - Control](./Vertex%20AI%20Pipelines%20-%20Control.ipynb)|An overview of controlling the flow of exectution for pipelines|\n",
    "||[Vertex AI Pipelines - Secret Manager](./Vertex%20AI%20Pipelines%20-%20Secret%20Manager.ipynb)|How to pass sensitive information to pipelines and components|\n",
    "||[Vertex AI Pipelines - Scheduling](./Vertex%20AI%20Pipelines%20-%20Scheduling.ipynb)|How to schedule pipeline execution|\n",
    "||[Vertex AI Pipelines - Management](./Vertex%20AI%20Pipelines%20-%20Management.ipynb)|Managing, Reusing, and Storing pipelines and components|\n",
    "||[Vertex AI Experiments](./Vertex%20AI%20Experiments.ipynb)|Understanding and using Vertex AI Experiments|\n",
    "\n",
    "To discover these notebooks as part of an introduction to MLOps [start here](./readme.md)!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7e678-d1ad-42f6-8eb5-9d3ca73c49c6",
   "metadata": {},
   "source": [
    "# Vertex AI Piplines - IO\n",
    "\n",
    "[Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) is a serverless  runner for Kubeflow Pipelines [(KFP)](https://www.kubeflow.org/docs/components/pipelines/v2/introduction/) and the [TensorFlow Extended (TFX)](ttps://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) framework.\n",
    "\n",
    "Components are used to run the steps of a pipelines.  A pipeline task runs the component with inputs and results in the components outputs.  The components execute code on compute with a container image.  And all the inputs and outputs are logged as pipeline metadata - automatically!\n",
    "\n",
    "This notebook will focus on the different data types for inputs and outputs to components.\n",
    "\n",
    "**Parameters** are Python objects like `str`, `int`, `float`, `bool`, `list`, `dict` objects that are defined as inputs to pipelines and components. Components can also return parameters for input into subsequent components. Paramters are excellent for changing the behavior of a pipeline/component through inputs rather than rewriting code.\n",
    "- [KFP Parameters](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/parameters/)\n",
    "\n",
    "**Artifacts** are multi-parameter objects that represent machine learning artifacts and have defined schemas and are stored as metadata with lineage.  The artifact schemas follow the [ML Metadata (MLMD)](https://github.com/google/ml-metadata) client library.  This helps with understanding and analyzing a pipeline.\n",
    "- [KFP Artifacts](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/)\n",
    "    - provided [artifact types](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/#artifact-types)\n",
    "    - [Google Cloud Artifact Types](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.0.0/api/artifact_types.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbd642-b4b6-406d-8686-5c02b3af4ed6",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602eac30-3606-435d-a079-d1b9db688990",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d9bea9-1567-4c5e-99c9-dd6caf1c9abc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46f84a-a0b7-49fb-a277-fff79394c0ed",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf619d0-ac63-47d9-8e68-805b9b366b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('kfp', 'kfp'),\n",
    "    ('google_cloud_pipeline_components', 'google-cloud-pipeline-components'),\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766d3aa-8efa-42b7-a355-f4108a089a33",
   "metadata": {},
   "source": [
    "## API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbac5cbe-87e7-4569-8dac-c74c910a800a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e053e-4386-490a-8200-ec0bf060fefc",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4eb5cf-ad4d-4a5f-8e00-a9369b21f5df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1829ae7-121e-445c-bb8f-6dc29f69fdf0",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d9aed-510f-4a52-ba06-02c18766f4f2",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d77108-5ced-43a5-9348-68face53ee99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd40bff4-7e8c-4520-8246-cccd7783ec86",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'pipeline-io'\n",
    "SERIES = 'mlops'\n",
    "\n",
    "# gcs bucket\n",
    "GCS_BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632a67ea-fb37-402b-b2d0-43df633a2f7b",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9025f7b-56fe-436c-9827-e959c8639f0f",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import importlib\n",
    "from google.cloud import aiplatform\n",
    "import kfp\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ee59c4-31a7-4d9b-b62a-1de226650d98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae3d6b8-202f-4df3-a031-72b084b80919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.51.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e563f7-a09c-4746-abf5-a906be394b5b",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c07f984-7130-402d-bb3c-fc400b0283bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c47247-7db0-4ae8-a537-2ebe2add47d2",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4bc595-17aa-41e9-9f9b-f91632602671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"temp/{SERIES}-{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ee51d9-77c8-4771-990e-0a05db6aa968",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92fa0b-2566-4607-9f3f-fda7a0b01b95",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc119f6-47d7-48d4-aef2-9681074a4cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9189c5-d8d7-4aef-a7a5-c9af2a8e778c",
   "metadata": {},
   "source": [
    "---\n",
    "## Parameters\n",
    "\n",
    "**Parameters** are Python objects like `str`, `int`, `float`, `bool`, `list`, `dict` objects that are defined as inputs to pipelines and components. Components can also return parameters for input into subsequent components. Paramters are excellent for changing the behavior of a pipeline/component through inputs rather than rewriting code.\n",
    "- [KFP Parameters](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/parameters/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b71d8-c1a7-418e-98c4-803c0f47c65f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Inputs and Output\n",
    "\n",
    "An example pipeline that has all the types of input parameters and outputs a single parameter:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1ce3e-ab80-46af-8d8a-4e6121665058",
   "metadata": {},
   "source": [
    "#### Create Pipeline Components\n",
    "\n",
    "These are simple Python components, specifically lightweight Python components and container components.  For more details on the types of components check out this workflow in the same repository:\n",
    "- [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba9066-992b-4294-be7b-2017be63f735",
   "metadata": {},
   "source": [
    "A simple lightweight python component with single input and single output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2d254576-c254-41b7-993a-ea0eefc3eea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\"]\n",
    ")\n",
    "def single_input(string: str) -> str:\n",
    "    text = string\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa82050-8ec6-4228-81b3-1099bd90b11d",
   "metadata": {},
   "source": [
    "A lightweight python component with multiple inputs and a single output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0c2432a9-69ab-4ade-ac04-3b5d4eaf6b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\"]\n",
    ")\n",
    "def multi_input(\n",
    "    a_str: str,\n",
    "    a_int: int,\n",
    "    a_float: float,\n",
    "    a_bool: bool,\n",
    "    a_dict: dict,\n",
    "    a_list: list\n",
    ") -> list:\n",
    "    text = [a_str, a_int, a_float, a_bool, a_dict, a_list]\n",
    "    return [str(t) for t in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4ea67-66e6-49e4-862c-da3a210be9f5",
   "metadata": {},
   "source": [
    "A container component with a single input and single output.  Note that this type of component using the [`kfp.dsl.OutputPath`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.OutputPath) to return the output to an object that looks like an input:\n",
    "- The shell command for `mkdir` is used to create an output loation  with the `kfp.dsl.OutputPath` variable\n",
    "- The `echo` command along with the `>` write to instruction are used to write values to the `kfp.dsl_OutputPath` using the directory created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f4e9dfa0-e592-4899-91ab-e70e571526ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.container_component\n",
    "def io_container(\n",
    "    in_str: str,\n",
    "    out_str: kfp.dsl.OutputPath(str)\n",
    "):\n",
    "    return kfp.dsl.ContainerSpec(\n",
    "        image = 'alpine',\n",
    "        command = [\n",
    "            'sh', '-c',  f'''mkdir -p $(dirname {out_str})\\\n",
    "                            && echo \"echoing {in_str}\" > {out_str}'''\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8930d-e632-453e-a66f-20ec53fb76c6",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e9e4cb25-a255-4c2e-b24f-945db913a63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = f'{SERIES}-{EXPERIMENT}-parameter-io'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5930c86c-5568-4ac8-b4f5-45892aed5fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name = pipeline_name,\n",
    "    description = 'A simple pipeline for testing',\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root'\n",
    ")\n",
    "def example_pipeline(\n",
    "    a_str: str,\n",
    "    a_int: int,\n",
    "    a_float: float,\n",
    "    a_bool: bool,\n",
    "    a_dict: dict,\n",
    "    a_list: list\n",
    ") -> list:\n",
    "    \n",
    "    single_io = single_input(string = a_str)\n",
    "    multi_i = multi_input(\n",
    "        a_str = single_io.output,\n",
    "        a_int= a_int,\n",
    "        a_float= a_float,\n",
    "        a_bool = a_bool,\n",
    "        a_dict = a_dict,\n",
    "        a_list = a_list   \n",
    "    )\n",
    "    container_io = io_container(in_str = single_io.output)\n",
    "    \n",
    "    return multi_i.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2f58e-8485-47ad-9afa-16555926e4c6",
   "metadata": {},
   "source": [
    "#### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d0f94cc2-61aa-4d36-b333-15af73f3dd9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = example_pipeline,\n",
    "    package_path = f'{DIR}/{pipeline_name}.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3843fed-315d-4835-a67e-ffa60c401842",
   "metadata": {},
   "source": [
    "#### Create Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "99506b8a-6fe7-48d3-af4a-64af87540368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    a_str = 'test string',\n",
    "    a_int = 1,\n",
    "    a_float = 1.2,\n",
    "    a_bool = True,\n",
    "    a_dict = dict(key = 45),\n",
    "    a_list = [1, 2, 3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "75d77f8d-1a15-4791-b95a-b5ac85986a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = pipeline_name,\n",
    "    template_path = f\"{DIR}/{pipeline_name}.yaml\",\n",
    "    parameter_values = parameters,\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = None # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef190bf-35e9-46af-8eff-7283c974a9b0",
   "metadata": {},
   "source": [
    "#### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d85d67f0-4d11-4d03-ae2d-92e3a6a142da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20240507115117\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20240507115117')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-parameter-io-20240507115117?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4f54890d-ce67-4012-b8a8-b41fda947d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-parameter-io-20240507115117?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "32bd4fe7-beb7-4373-b499-c1b90b1a97bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20240507115117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20240507115117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20240507115117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20240507115117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20240507115117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20240507115117\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0e810-ca9a-43b1-bcf7-63e2e5edfbd3",
   "metadata": {},
   "source": [
    "#### Retrieve Pipeline Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "127f461e-6d87-4b68-9562-928b7a1e53c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.input:a_dict</th>\n",
       "      <th>param.input:a_list</th>\n",
       "      <th>param.input:a_str</th>\n",
       "      <th>param.input:a_float</th>\n",
       "      <th>param.input:a_bool</th>\n",
       "      <th>param.input:a_int</th>\n",
       "      <th>param.vmlmd_lineage_integration</th>\n",
       "      <th>param.output:Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlops-pipeline-io-parameter-io</td>\n",
       "      <td>mlops-pipeline-io-parameter-io-20240507115117</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "      <td>test string</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>[test string, 1, 1.2, True, {'key': 45}, [1, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pipeline_name  \\\n",
       "0  mlops-pipeline-io-parameter-io   \n",
       "\n",
       "                                        run_name param.input:a_dict  \\\n",
       "0  mlops-pipeline-io-parameter-io-20240507115117      {'key': 45.0}   \n",
       "\n",
       "  param.input:a_list param.input:a_str  param.input:a_float  \\\n",
       "0    [1.0, 2.0, 3.0]       test string                  1.2   \n",
       "\n",
       "   param.input:a_bool  param.input:a_int  \\\n",
       "0                True                1.0   \n",
       "\n",
       "                     param.vmlmd_lineage_integration  \\\n",
       "0  {'pipeline_run_component': {'location_id': 'us...   \n",
       "\n",
       "                                 param.output:Output  \n",
       "0  [test string, 1, 1.2, True, {'key': 45}, [1, 2...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'{pipeline_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "003fd409-0a89-4937-a970-7f6f49f9b0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = {task.task_name: task for task in pipeline_job.task_details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9e6e6303-4b9d-4d05-8413-9001ba0cdbf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlops-pipeline-io-parameter-io-20240507115117 State.SUCCEEDED\n",
      "multi-input State.SUCCEEDED\n",
      "io-container State.SUCCEEDED\n",
      "single-input State.SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "  print(task, tasks[task].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d6c6e5b0-194f-4b54-9181-fe1c33c0eef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tasks['io-container']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f9629-05c1-4b33-8038-bd86f2682fbd",
   "metadata": {},
   "source": [
    "---\n",
    "### Multiple Outputs\n",
    "\n",
    "How to handle multiple output parameters when there is a single output object?  This is possible in pipelines components by using the [`typing` modules](https://docs.python.org/3/library/typing.html#module-typing) [`NamedTuple`](https://docs.python.org/3/library/typing.html#typing.NamedTuple) implementation.  The are tuples with named fields, meaning, that fields can be accessed by name instead of position indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628fd64-0e01-4b98-839a-298f54859b1e",
   "metadata": {},
   "source": [
    "#### Understanding `NamedTuple`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7254ef-bcd0-4415-b614-943ab85578bd",
   "metadata": {},
   "source": [
    "First, are regular tuple.  The following creates a tuple and then recalls the 3rd element with an index.  At first this might seem like a list in Python but tuples are immutable objects - elements cannot be modified, added, or removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "81923be9-e0d2-4596-bf3c-9b55ea44b3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_tuple = (1, 'string', 4.5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d1e54728-7ef5-46e9-8246-62d81cb8b32a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tuple[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef5f78-bb04-47d8-873c-980883379229",
   "metadata": {},
   "source": [
    "Now, a named tuple.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0e0ca37c-e159-49b9-845d-5aec91df9769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_named_tuple = NamedTuple('example', x=int, y=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c072f0f9-17ad-4968-9765-591c0acd9dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_tuple = example_named_tuple(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ec151e48-c393-4112-85a3-d968427a505f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example(x=4, y=8)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e73c9c8a-eba0-48f3-a220-750e736c4554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tuple.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a189bf-3dff-4101-9c7f-25df87ab63e7",
   "metadata": {},
   "source": [
    "Also, define and populate all at once like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "62e6d6e1-224b-46e4-aa0c-200ea033e168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example(x=2, y=9)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NamedTuple('example', x=int, y=int)(2, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5eb202-081f-4edd-b067-1f841f3d95ca",
   "metadata": {},
   "source": [
    "#### Create Pipeline Components\n",
    "\n",
    "These are simple Python components, specifically lightweight Python components and container components.  For more details on the types of components check out this workflow in the same repository:\n",
    "- [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeda78c-777e-4cdb-b342-5332005ceaa8",
   "metadata": {},
   "source": [
    "A lightweight python component with multiple inputs and multiple outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "650b6d9f-8c7e-455c-bf5f-fe7ca2100e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\"]\n",
    ")\n",
    "def multi_input_output(\n",
    "    a_str: str,\n",
    "    a_int: int,\n",
    "    a_float: float,\n",
    "    a_bool: bool,\n",
    "    a_dict: dict,\n",
    "    a_list: list\n",
    ") -> NamedTuple('multi_output', b_str=str, b_int=int, b_float=float, b_bool=bool, b_dict=dict, b_list=list):\n",
    "    from typing import NamedTuple\n",
    "    output = NamedTuple('multi_output', b_str=str, b_int=int, b_float=float, b_bool=bool, b_dict=dict, b_list=list)\n",
    "    return output(a_str, a_int, a_float, a_bool, a_dict, a_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11737e06-b7cd-4ddd-9bfa-b1ca2043b37e",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fc3b39d1-f7da-4b79-a6a6-d0ce78b4486a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = f'{SERIES}-{EXPERIMENT}-parameter-multi-io'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e4da685b-225e-4600-a3ea-7fe451f4894e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name = pipeline_name,\n",
    "    description = 'A simple pipeline for testing',\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root'\n",
    ")\n",
    "def example_pipeline(\n",
    "    a_str: str,\n",
    "    a_int: int,\n",
    "    a_float: float,\n",
    "    a_bool: bool,\n",
    "    a_dict: dict,\n",
    "    a_list: list\n",
    ") -> list:\n",
    "    \n",
    "    multi_io = multi_input_output(\n",
    "        a_str = a_str,\n",
    "        a_int= a_int,\n",
    "        a_float= a_float,\n",
    "        a_bool = a_bool,\n",
    "        a_dict = a_dict,\n",
    "        a_list = a_list \n",
    "    )\n",
    "    multi_i = multi_input(\n",
    "        a_str = multi_io.outputs['b_str'],\n",
    "        a_int= multi_io.outputs['b_int'],\n",
    "        a_float= multi_io.outputs['b_float'],\n",
    "        a_bool = multi_io.outputs['b_bool'],\n",
    "        a_dict = multi_io.outputs['b_dict'],\n",
    "        a_list = multi_io.outputs['b_list']   \n",
    "    )\n",
    "    \n",
    "    return multi_i.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f68190-6495-42a6-b821-f3a9a2a20993",
   "metadata": {},
   "source": [
    "#### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e7264d29-7548-4a6e-ad29-7e8a005a55a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = example_pipeline,\n",
    "    package_path = f'{DIR}/{pipeline_name}.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c940e2de-9a83-4165-8079-c16c6fbc226b",
   "metadata": {},
   "source": [
    "#### Create Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4f82973d-0f9c-406f-bdf6-07f14b1fa013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    a_str = 'test string',\n",
    "    a_int = 1,\n",
    "    a_float = 1.2,\n",
    "    a_bool = True,\n",
    "    a_dict = dict(key = 45),\n",
    "    a_list = [1, 2, 3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a9cb62ed-9e66-40ca-9c74-d4703953f020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = pipeline_name,\n",
    "    template_path = f\"{DIR}/{pipeline_name}.yaml\",\n",
    "    parameter_values = parameters,\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = None # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ad519-f9ae-4ced-aab9-cb42964d4bd2",
   "metadata": {},
   "source": [
    "#### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1d9d06fe-ce77-40b0-8eea-8b555982d526",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20240507123009\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20240507123009')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-parameter-multi-io-20240507123009?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f25fdc8d-d61b-4b0c-a587-aa7493aab440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-parameter-multi-io-20240507123009?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2250c5e4-40a7-4a5c-9128-988b79394b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20240507123009 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20240507123009 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20240507123009 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20240507123009 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20240507123009 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20240507123009\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b4242c-6113-4409-91b2-2aad6646b0c2",
   "metadata": {},
   "source": [
    "#### Retrieve Pipeline Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c662c-7a82-424f-8d04-3b05fde07d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'{pipeline_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "12c50b08-4a6e-44b9-b5dc-e4d1f3685768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = {task.task_name: task for task in pipeline_job.task_details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d824941f-62ce-41ac-abb0-9ba058daabd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input State.SUCCEEDED\n",
      "multi-input-output State.SUCCEEDED\n",
      "mlops-pipeline-io-parameter-multi-io-20240507123009 State.SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "  print(task, tasks[task].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "da07aff4-720f-402c-add5-bf8d0486a439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tasks['multi-input-output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee04af-71d9-43cf-8cc7-a7d1cb9f9162",
   "metadata": {},
   "source": [
    "---\n",
    "## Artifacts: `kfp` Artifacts\n",
    "\n",
    "**Artifacts** are multi-parameter objects that represent machine learning artifacts and have defined schemas and are stored as metadata with lineage.  The artifact schemas follow the [ML Metadata (MLMD)](https://github.com/google/ml-metadata) client library.  This helps with understanding and analyzing a pipeline.\n",
    "- [KFP Artifacts](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/)\n",
    "    - provided [artifact types](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/#artifact-types)\n",
    "    - [Google Cloud Artifact Types](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.0.0/api/artifact_types.html)\n",
    "    \n",
    "Artifacts are like other input parameters and output parameters and can be passed directly with the artifact class as a parameter.  For returning multiple artifacts use the same `NamedTuple` approach covered under parameters above.\n",
    "\n",
    "For Example:\n",
    "```Python\n",
    "import kfp\n",
    "\n",
    "@kfp.dsl.component()\n",
    "def new_component(input_artifact: kfp.dsl.Artifact) > kfp.dsl.Artifact:\n",
    "    ...\n",
    "    return kfp.dsl.Artifact\n",
    "```\n",
    "\n",
    "---\n",
    "**NOTE:** This is different than you may have seen in earlier `kfp` pipeline implementations.  Previously, artifacts were passed to and from components with input parameters that were defined with wrapper classes:\n",
    "- `kfp.dsl.Input`\n",
    "- `kfp.dsl.Output`\n",
    "\n",
    "See more information at [traditional artifact syntax](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/#traditional-artifact-syntax)\n",
    "\n",
    "---\n",
    "    \n",
    "    \n",
    "There are generic artifacts available directly through `kfp` so you don't need to define custom ones (more later on importing additional artifiacts):\n",
    "|Artifact Object|Schema Name|Description|\n",
    "|---|---|---|\n",
    "|[`kfp.dsl.Artifact`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Artifact)|`system.Artifact`|Generic Artifact|\n",
    "|[`kfp.dsl.Dataset`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Dataset)|`system.Dataset`|Dataset Object|\n",
    "|[`kfp.dsl.Model`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Model)|`system.Model`|Model Object|\n",
    "|[`kfp.dsl.Metrics`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Metrics)|`system.Metrics`|Key:value scalar metrics (accuracy, precision, recall, ...)|\n",
    "|[`kfp.dsl.ClassificationMetrics`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.ClassificationMetrics)|`system.ClassificationMetrics`|Classificaiton Metrics (ROC, consion matrix)|\n",
    "|[`kfp.dsl.SlicedClassificationMetrics`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.SlicedClassificationMetrics)|`system.SlicedClassificationMetrics`|Classification Metrics (ROC, confusion matrix) for slices of data|\n",
    "|[`kfp.dsl.HTML`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.HTML)|`system.HTML`|An HTML file|\n",
    "|[`kfp.dsl.Markdown`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Markdown)|`system.Markdown`|A Markdown file|\n",
    "\n",
    "These objects each have parameters:\n",
    "- `name` is the name of the artifact.  Vertex AI Pipelines automatically assigns this name to the metadata resource location and **cannot be overriden**.\n",
    "- `uri` is the uri to artifacts location.  Vertex AI Pipelines automatically assigns a location based on the `aiplatform.PipelineJob(pipeline_root = 'gs://...')` value but **can be overridden** to another location.\n",
    "- `metadata` is a `dict` of key:value pairs describing the object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bcaa21-72b1-4fe0-92be-ceed841c989d",
   "metadata": {},
   "source": [
    "## Artifacts: Google Cloud Artifact Types\n",
    "\n",
    "In addition to the `kfp` provided architect types, there are also libraries of artifacts for native Google Cloud Artifacts.  Everything from BigQuery Table, BigQuery ML Models, to Vertex AI Models and Vertex AI Endpoints.  These are included with the [Google Cloud Pipeline Components SDK](https://cloud.google.com/vertex-ai/docs/pipelines/components-introduction) which also include GCP specific pre-built components as covered in the components workflow at see [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39252cad-fa1a-490b-893f-4be20b8604fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.types import artifact_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5c5ad-8514-4d6b-8554-be22b882fc0d",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipeline With Artifacts\n",
    "\n",
    "An example pipeline that makes use of:\n",
    "- all 8 `kfp` artifact types and multiple Google Cloud Artifact Types\n",
    "- passing artifacts as outputs and intput between components\n",
    "- returning multiple artifacts from components\n",
    "- saving content for multiple artifacts with the same component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e07a5-8ae6-4dcd-a8d1-6fd0ec1bf962",
   "metadata": {},
   "source": [
    "### Create Pipeline Components\n",
    "\n",
    "These are simple Python components, specifically lightweight Python components.  For more details on the types of components check out this workflow in the same repository:\n",
    "- [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9291e57-7262-468a-a015-a74a010e4fb9",
   "metadata": {},
   "source": [
    "#### Component: `data_source`\n",
    "\n",
    "This component defines an artifact that points to the data source in place, in BigQuery.  It uses the Google Cloud Artifact Type for BigQuery Tables: [`google_cloud_pipeline_components.types.artifact_types.BQTable()`](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.14.0/api/artifact_types.html#google_cloud_pipeline_components.types.artifact_types.BQTable).\n",
    "\n",
    ">**NOTE:** This could be done with an importer component `kfp.dsl.importer` - see [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "765cc393-ffbf-425c-af45-0edea9db45a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"google-cloud-pipeline-components\"]\n",
    ")\n",
    "def data_source(\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    bq_table_artifact: kfp.dsl.Output[artifact_types.BQTable]\n",
    "):\n",
    "    \n",
    "    bq_table_artifact.uri = f'https://www.googleapis.com/bigquery/v2/projects/{bq_project}/datasets/{bq_dataset}/tables/{bq_table}'\n",
    "    bq_table_artifact.metadata['projectId'] = bq_project\n",
    "    bq_table_artifact.metadata['datasetId'] = bq_dataset\n",
    "    bq_table_artifact.metadata['tableId'] = bq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93420d86-3805-4ddb-8840-d9e8108c159e",
   "metadata": {},
   "source": [
    "#### Component: `data_prep`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- read data from BigQuery Table using Input Artifact for BigQuery Table\n",
    "- split data in the train, eval, text\n",
    "- create output artifacts (`kfp.dsl.Dataset`) for each split of the data\n",
    "- create output artifact (`kfp.dsl.Artifact`) with feature information from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "78442045-b769-4ac4-b871-eaf1d0d9891c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"google-cloud-pipeline-components\", \"bigframes\", \"scikit-learn\"]\n",
    ")\n",
    "def data_prep(\n",
    "    project_id: str,\n",
    "    bq_source: kfp.dsl.Input[artifact_types.BQTable],\n",
    ") -> NamedTuple(\n",
    "        'output',\n",
    "        train=kfp.dsl.Dataset,\n",
    "        test=kfp.dsl.Dataset,\n",
    "        features=kfp.dsl.Artifact\n",
    "):\n",
    "    from typing import NamedTuple\n",
    "    outputs = NamedTuple(\n",
    "            'output',\n",
    "            train=kfp.dsl.Dataset,\n",
    "            test=kfp.dsl.Dataset,\n",
    "            features=kfp.dsl.Artifact\n",
    "    )\n",
    "    \n",
    "    # connect to BigQuery table, ELT, read to local\n",
    "    import bigframes.pandas as bpd\n",
    "    bpd.options.bigquery.project = project_id\n",
    "    bpd.options.bigquery.location = 'us'\n",
    "    ds = bpd.read_gbq(f\"{bq_source.metadata['projectId']}.{bq_source.metadata['datasetId']}.{bq_source.metadata['tableId']}\")\n",
    "    # fix data quality issue\n",
    "    ds['sex'] = ds['sex'].replace('.', None)\n",
    "    full_ds = ds.to_pandas()\n",
    "    \n",
    "    # split data into train/test\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_ds, test_ds = train_test_split(full_ds, test_size = 0.25)\n",
    "    \n",
    "    # write test and train to Dataset artifacts - with specific subfolders\n",
    "    import os\n",
    "    #train\n",
    "    train = kfp.dsl.Dataset(\n",
    "        uri = kfp.dsl.get_uri(suffix = 'train'),\n",
    "        metadata = dict(\n",
    "            samples = train_ds.shape[0],\n",
    "            filename = 'data.txt'\n",
    "        )\n",
    "    )\n",
    "    path = train.path + '/data.txt'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok = True)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(train_ds.to_json(orient='records'))\n",
    "    # test    \n",
    "    test = kfp.dsl.Dataset(\n",
    "        uri = kfp.dsl.get_uri(suffix = 'test'),\n",
    "        metadata = dict(\n",
    "            samples = test_ds.shape[0],\n",
    "            filename = 'data.txt'\n",
    "        )\n",
    "    )\n",
    "    path = test.path + '/data.txt'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok = True)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(test_ds.to_json(orient='records'))\n",
    "    \n",
    "    # add feature info the feature Artifact\n",
    "    features = kfp.dsl.Artifact(\n",
    "        metadata = dict(\n",
    "            label_col = 'species',\n",
    "            label_values = ds['species'].unique().to_list(),\n",
    "            train_n = train_ds.shape[0],\n",
    "            test_n = test_ds.shape[0],\n",
    "            features = [x for x in ds.columns.to_list() if x != 'species']\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return outputs(train, test, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18facd9-fa73-485e-8a4b-99e2496fed6f",
   "metadata": {},
   "source": [
    "#### Component: `model_gb`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- inputs artifacts for training data as well as feature information created by the `data_prep` component\n",
    "- creates a model with `sklearn.ensemble.GradientBoostingClassifier`\n",
    "- output artifact for the model (`kfp.dsl.Model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "730923c9-86b4-4a66-9b9d-5e9716fbaf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\", \"scikit-learn\"]\n",
    ")\n",
    "def model_gb(\n",
    "    train: kfp.dsl.Dataset,\n",
    "    features: kfp.dsl.Artifact\n",
    ") -> kfp.dsl.Model:\n",
    "    \n",
    "    # import data\n",
    "    import pandas as pd\n",
    "    from io import StringIO\n",
    "    with open(train.path + f\"/{train.metadata['filename']}\", 'r') as f:\n",
    "        train_ds = f.read()\n",
    "    train_ds = pd.read_json(StringIO(train_ds), orient='records')\n",
    "    \n",
    "    # prepare data for training: split the features (x) and label (y)\n",
    "    train_x = train_ds[features.metadata['features']]\n",
    "    train_y = train_ds[features.metadata['label_col']] \n",
    "    \n",
    "    # create pipeline with preprocessing and training\n",
    "    import sklearn.ensemble\n",
    "    import sklearn.impute\n",
    "    import sklearn.pipeline\n",
    "    import sklearn.preprocessing\n",
    "    import sklearn.compose\n",
    "    import numpy as np\n",
    "    numerical_transformer = sklearn.pipeline.Pipeline([\n",
    "        ('imputer', sklearn.impute.SimpleImputer(strategy = 'mean')),\n",
    "        ('scaler', sklearn.preprocessing.MinMaxScaler()),\n",
    "    ])\n",
    "    categorical_transformer = sklearn.pipeline.Pipeline([\n",
    "        ('imputer', sklearn.impute.SimpleImputer(strategy = 'most_frequent', add_indicator = True)),\n",
    "        ('encoder', sklearn.preprocessing.OrdinalEncoder()),\n",
    "    ])\n",
    "    preprocessor = sklearn.compose.ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('numerical', numerical_transformer, [c for c in train_x.columns if train_x[c].isna().any() and train_x[c].dtypes == 'float64']),\n",
    "            ('categorical', categorical_transformer, [c for c in train_x.columns if train_x[c].isna().any() and train_x[c].dtypes == 'object'])\n",
    "        ]\n",
    "    )\n",
    "    pipeline = sklearn.pipeline.Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', sklearn.ensemble.GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.125, max_depth = 3)),\n",
    "    ])\n",
    "    \n",
    "    # fit/train model\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    \n",
    "    # save model and create artifact\n",
    "    import pickle, os\n",
    "    model = kfp.dsl.Model(\n",
    "        uri = kfp.dsl.get_uri(),\n",
    "        metadata = dict(\n",
    "            accuracy = pipeline.score(train_x, train_y)\n",
    "        )\n",
    "    )\n",
    "    path = model.path + '/model.pkl'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok = True)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45702654-8195-4ed4-a4f4-b08b51acaff6",
   "metadata": {},
   "source": [
    "#### Component: `model_rf`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- inputs artifacts for training data as well as feature information created by the `data_prep` component\n",
    "- creates a model with `sklearn.ensemble.RandomForestClassifier`\n",
    "- output artifacts for the model (`kfp.dsl.Model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "3d2d6381-d60f-4bb0-8825-94fcf1b4807e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\", \"scikit-learn\"]\n",
    ")\n",
    "def model_rf(\n",
    "    train: kfp.dsl.Dataset,\n",
    "    features: kfp.dsl.Artifact\n",
    ") -> kfp.dsl.Model:\n",
    "    \n",
    "    # import data\n",
    "    import pandas as pd\n",
    "    from io import StringIO\n",
    "    with open(train.path + f\"/{train.metadata['filename']}\", 'r') as f:\n",
    "        train_ds = f.read()\n",
    "    train_ds = pd.read_json(StringIO(train_ds), orient='records')\n",
    "    \n",
    "    # prepare data for training: split the features (x) and label (y)\n",
    "    train_x = train_ds[features.metadata['features']]\n",
    "    train_y = train_ds[features.metadata['label_col']] \n",
    "    \n",
    "    # create pipeline with preprocessing and training\n",
    "    import sklearn.ensemble\n",
    "    import sklearn.impute\n",
    "    import sklearn.pipeline\n",
    "    import sklearn.preprocessing\n",
    "    import sklearn.compose\n",
    "    import numpy as np\n",
    "    numerical_transformer = sklearn.pipeline.Pipeline([\n",
    "        ('imputer', sklearn.impute.SimpleImputer(strategy = 'mean')),\n",
    "        ('scaler', sklearn.preprocessing.MinMaxScaler()),\n",
    "    ])\n",
    "    categorical_transformer = sklearn.pipeline.Pipeline([\n",
    "        ('imputer', sklearn.impute.SimpleImputer(strategy = 'most_frequent', add_indicator = True)),\n",
    "        ('encoder', sklearn.preprocessing.OrdinalEncoder()),\n",
    "    ])\n",
    "    preprocessor = sklearn.compose.ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('numerical', numerical_transformer, [c for c in train_x.columns if train_x[c].isna().any() and train_x[c].dtypes == 'float64']),\n",
    "            ('categorical', categorical_transformer, [c for c in train_x.columns if train_x[c].isna().any() and train_x[c].dtypes == 'object'])\n",
    "        ]\n",
    "    )\n",
    "    pipeline = sklearn.pipeline.Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', sklearn.ensemble.RandomForestClassifier(n_estimators = 200, max_depth = 3)),\n",
    "    ])\n",
    "    \n",
    "    # fit/train model\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    \n",
    "    # save model and create artifact\n",
    "    import pickle, os\n",
    "    model = kfp.dsl.Model(\n",
    "        uri = kfp.dsl.get_uri(),\n",
    "        metadata = dict(\n",
    "            accuracy = pipeline.score(train_x, train_y)\n",
    "        )\n",
    "    )\n",
    "    path = model.path + '/model.pkl'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok = True)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c207652-8096-4895-88af-d8228d172c77",
   "metadata": {},
   "source": [
    "#### Component: `metrics`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- inputs artifacts for a dataset and a model\n",
    "- create artifacts for:\n",
    "    - Metrics with `kfp.dsl.Metrics`\n",
    "    - Classification metrics with `kfp.dsl.ClassificationMetrics`\n",
    "    - Sliced Classification metrics wtih `kfp.dsl.SlicedClassificationMetrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "b55ee56c-7969-4c38-9a7d-eeb6480651de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\", \"numpy\", \"scikit-learn\"]\n",
    ")\n",
    "def metrics(\n",
    "    data: kfp.dsl.Dataset,\n",
    "    features: kfp.dsl.Artifact,\n",
    "    model: kfp.dsl.Model\n",
    ") -> NamedTuple(\n",
    "        'output',\n",
    "        metrics=kfp.dsl.Metrics,\n",
    "        class_metrics=kfp.dsl.ClassificationMetrics,\n",
    "        #slice_class_metrics=kfp.dsl.SlicedClassificationMetrics\n",
    "):\n",
    "    from typing import NamedTuple\n",
    "    outputs = NamedTuple(\n",
    "            'output',\n",
    "            metrics=kfp.dsl.Metrics,\n",
    "            class_metrics=kfp.dsl.ClassificationMetrics,\n",
    "            #slice_class_metrics=kfp.dsl.SlicedClassificationMetrics\n",
    "    )\n",
    "    \n",
    "    # import data\n",
    "    import pandas as pd\n",
    "    from io import StringIO\n",
    "    with open(data.path + f\"/{data.metadata['filename']}\", 'r') as f:\n",
    "        ds = f.read()\n",
    "    ds = pd.read_json(StringIO(ds), orient='records')\n",
    "    \n",
    "    # get the ground truth\n",
    "    x = ds[features.metadata['features']]\n",
    "    y = ds[features.metadata['label_col']]\n",
    "    \n",
    "    # import model\n",
    "    import pickle\n",
    "    with open(model.path+'/model.pkl', 'rb') as f:\n",
    "        classifier = pickle.load(f)\n",
    "    pred = classifier.predict(x)\n",
    "    proba = classifier.predict_proba(x)\n",
    "    \n",
    "    # metrics artifact\n",
    "    import sklearn.metrics\n",
    "    metrics = kfp.dsl.Metrics()\n",
    "    metrics.log_metric('accuracy', classifier.score(x, y))\n",
    "    if len(features.metadata['label_values'])>2:\n",
    "        metrics.log_metric('precision', sklearn.metrics.precision_score(y, pred, average='macro'))\n",
    "        metrics.log_metric('recall', sklearn.metrics.recall_score(y, pred, average='macro'))\n",
    "        metrics.log_metric('f1', sklearn.metrics.f1_score(y, pred, average='macro'))\n",
    "        metrics.log_metric('average_precision', sklearn.metrics.average_precision_score(y, proba, average='macro'))\n",
    "    else:\n",
    "        metrics.log_metric('precision', sklearn.metrics.precision_score(y, pred, average='binary'))\n",
    "        metrics.log_metric('recall', sklearn.metrics.recall_score(y, pred, average='binary'))\n",
    "        metrics.log_metric('f1', sklearn.metrics.f1_score(y, pred, average='binary'))\n",
    "        metrics.log_metric('average_precision', sklearn.metrics.average_precision_score(y, proba, average='binary'))\n",
    "    \n",
    "    # classification metrics artifact\n",
    "    class_metrics = kfp.dsl.ClassificationMetrics()\n",
    "    class_metrics.log_confusion_matrix(\n",
    "        categories = classifier.classes_,\n",
    "        matrix = sklearn.metrics.confusion_matrix(y, pred).tolist()\n",
    "    )\n",
    "    \n",
    "    # sliced classification metrics artifact\n",
    "    #import numpy as np\n",
    "    #import sklearn.preprocessing\n",
    "    #slice_class_metrics = kfp.dsl.SlicedClassificationMetrics()\n",
    "    #labeler = sklearn.preprocessing.LabelBinarizer().fit(y)\n",
    "    #for c in classifier.classes_:\n",
    "    #    i = np.where(labeler.transform([c]) == 1)[0][0]\n",
    "    #    fpr, tpr, thresholds = sklearn.metrics.roc_curve(\n",
    "    #        y_true = labeler.transform(y)[:, i],\n",
    "    #        y_score = classifier.predict_proba(x)[:, i]\n",
    "    #    )\n",
    "    #    infs = [t==np.inf for t in thresholds.tolist()]\n",
    "    #    \n",
    "    #    slice_class_metrics.load_roc_readings(\n",
    "    #        c,\n",
    "    #        [\n",
    "    #            [t for i,t in enumerate(thresholds.tolist()) if infs[i]==True],\n",
    "    #            [t for i,t in enumerate(tpr.tolist()) if infs[i]==True],\n",
    "    #            [t for i,t in enumerate(fpr.tolist()) if infs[i]==True]\n",
    "    #        ]\n",
    "    #    )\n",
    "        \n",
    "                       \n",
    "    return outputs(metrics, class_metrics) #, slice_class_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c8d227-3fc6-446d-8cfd-799f6f2b13e3",
   "metadata": {},
   "source": [
    "#### Component: `overview`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- inputs a list of metric artifacts\n",
    "- create a `kfp.dsl.HTML` artifact\n",
    "- creates a `kfp.dsl.Markdown` artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "f9d32d46-e46b-4587-a14a-d0fb9c3fd1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\", \"tabulate\"]\n",
    ")\n",
    "def overview(\n",
    "    metrics_0: kfp.dsl.Metrics,\n",
    "    metrics_1: kfp.dsl.Metrics,\n",
    "    metrics_2: kfp.dsl.Metrics,\n",
    "    metrics_3: kfp.dsl.Metrics,\n",
    "    models: list,\n",
    "    data: list\n",
    ") -> NamedTuple(\n",
    "        'output',\n",
    "        html=kfp.dsl.HTML,\n",
    "        md=kfp.dsl.Markdown\n",
    "):\n",
    "    from typing import NamedTuple\n",
    "    outputs = NamedTuple(\n",
    "            'output',\n",
    "            html=kfp.dsl.HTML,\n",
    "            md=kfp.dsl.Markdown\n",
    "    )\n",
    "    \n",
    "    # construct dataframe\n",
    "    import pandas as pd\n",
    "    metrics = [metrics_0.metadata, metrics_1.metadata, metrics_2.metadata, metrics_3.metadata]\n",
    "    records = []\n",
    "    for m, metric in enumerate(metrics):\n",
    "        records.append(\n",
    "            dict(\n",
    "                model = models[m],\n",
    "                data = data[m]\n",
    "            )|metrics[m]\n",
    "        )\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # html artifact\n",
    "    html = kfp.dsl.HTML(uri = kfp.dsl.get_uri()[:-7])\n",
    "    with open(html.path+'/html.html', 'w') as f:\n",
    "        f.write(df.to_html(index = False))\n",
    "    \n",
    "    # markdown artifact\n",
    "    md = kfp.dsl.Markdown(uri = kfp.dsl.get_uri()[:-7])\n",
    "    with open(md.path+'/md.md', 'w') as f:\n",
    "        f.write(df.to_markdown(index = False))\n",
    "    \n",
    "    return outputs(html, md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0852c793-0e93-42fa-84d1-69f3f70649c3",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "c1eac05c-c30c-4c03-b920-deedd7370b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = f'{SERIES}-{EXPERIMENT}-artifacts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "345982f0-6b4f-46e1-b4ed-186da73249c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name = pipeline_name,\n",
    "    description = 'A simple pipeline for testing',\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root'\n",
    ")\n",
    "def pipeline(\n",
    "    project_id: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str\n",
    "):\n",
    "    \n",
    "    bq_source = data_source(\n",
    "        bq_project = bq_project,\n",
    "        bq_dataset = bq_dataset,\n",
    "        bq_table = bq_table\n",
    "    )\n",
    "    train_data = data_prep(\n",
    "        project_id = project_id,\n",
    "        bq_source = bq_source.output\n",
    "    )\n",
    "    model_1 = model_gb(\n",
    "        train = train_data.outputs['train'],\n",
    "        features = train_data.outputs['features']\n",
    "    )\n",
    "    model_2 = model_rf(\n",
    "        train = train_data.outputs['train'],\n",
    "        features = train_data.outputs['features']\n",
    "    )\n",
    "    metrics_1_train = metrics(\n",
    "        data = train_data.outputs['train'],\n",
    "        features = train_data.outputs['features'],\n",
    "        model = model_1.output,\n",
    "    ).set_display_name('Metrics: Training Data')\n",
    "    metrics_1_test = metrics(\n",
    "        data = train_data.outputs['test'],\n",
    "        features = train_data.outputs['features'],\n",
    "        model = model_1.output,\n",
    "    ).set_display_name('Metrics: Test Data')\n",
    "    metrics_2_train = metrics(\n",
    "        data = train_data.outputs['train'],\n",
    "        features = train_data.outputs['features'],\n",
    "        model = model_2.output,\n",
    "    ).set_display_name('Metrics: Training Data')\n",
    "    metrics_2_test = metrics(\n",
    "        data = train_data.outputs['test'],\n",
    "        features = train_data.outputs['features'],\n",
    "        model = model_2.output,\n",
    "    ).set_display_name('Metrics: Test Data')\n",
    "    \n",
    "    review = overview(\n",
    "        metrics_0 = metrics_1_train.outputs['metrics'],\n",
    "        metrics_1 = metrics_1_test.outputs['metrics'],\n",
    "        metrics_2 = metrics_2_train.outputs['metrics'],\n",
    "        metrics_3 = metrics_2_test.outputs['metrics'],\n",
    "        models = ['GB', 'GB', 'RF', 'RF'],\n",
    "        data = ['Train', 'Test', 'Train', 'Test']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958f76a-52af-4c20-9870-e7bb77ce009a",
   "metadata": {},
   "source": [
    "### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "912ca1b6-daaf-4193-a9be-35d3a6d7187f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = pipeline,\n",
    "    package_path = f'{DIR}/{pipeline_name}.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2347d333-927e-4e55-b1fb-c4922e69e6f7",
   "metadata": {},
   "source": [
    "### Create Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "8bc66761-42ba-447b-b591-5f2df62de6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    project_id = PROJECT_ID,\n",
    "    bq_project = 'bigquery-public-data',\n",
    "    bq_dataset = 'ml_datasets',\n",
    "    bq_table = 'penguins'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "2226ceab-9a6e-4b42-9fd8-3cdb8ae1ddc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = pipeline_name,\n",
    "    template_path = f\"{DIR}/{pipeline_name}.yaml\",\n",
    "    parameter_values = parameters,\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = None # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c28dcc-873f-47b1-a319-0524af4f59ce",
   "metadata": {},
   "source": [
    "### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "5d5eb4bf-7448-4d9c-a445-53418d2c029f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20240518022913\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20240518022913')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-artifacts-20240518022913?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "4dce19bb-c8bf-468a-b115-21410f5a800b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-artifacts-20240518022913?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "3234ae0b-d659-45fa-a436-638d234dcee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20240518022913 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20240518022913 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20240518022913 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20240518022913\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de9e00f-c93d-4c60-922d-1ecdf6d8ed3a",
   "metadata": {},
   "source": [
    "### Retrieve Pipeline Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "aa8ed08d-9bc7-4af3-877a-2e36bfc42094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.vmlmd_lineage_integration</th>\n",
       "      <th>param.input:project_id</th>\n",
       "      <th>param.input:bq_table</th>\n",
       "      <th>param.input:bq_dataset</th>\n",
       "      <th>param.vertex-ai-pipelines-artifact-argument-binding</th>\n",
       "      <th>param.input:bq_project</th>\n",
       "      <th>metric.accuracy</th>\n",
       "      <th>metric.average_precision</th>\n",
       "      <th>metric.recall</th>\n",
       "      <th>metric.f1</th>\n",
       "      <th>metric.precision</th>\n",
       "      <th>metric.confusionMatrix</th>\n",
       "      <th>param.input:uri</th>\n",
       "      <th>param.input:name</th>\n",
       "      <th>param.input:a_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518022913</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-4-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.992971</td>\n",
       "      <td>0.953692</td>\n",
       "      <td>0.952690</td>\n",
       "      <td>0.952112</td>\n",
       "      <td>{'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518022407</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-4-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.980620</td>\n",
       "      <td>0.995643</td>\n",
       "      <td>0.970428</td>\n",
       "      <td>0.975578</td>\n",
       "      <td>0.981203</td>\n",
       "      <td>{'rows': [{'row': [122.0, 0.0, 0.0]}, {'row': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518021747</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-4-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>0.951111</td>\n",
       "      <td>0.952079</td>\n",
       "      <td>0.953472</td>\n",
       "      <td>{'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518020958</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-4-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.996416</td>\n",
       "      <td>0.996838</td>\n",
       "      <td>0.997290</td>\n",
       "      <td>{'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518020753</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-4-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.980620</td>\n",
       "      <td>0.995643</td>\n",
       "      <td>0.970428</td>\n",
       "      <td>0.975578</td>\n",
       "      <td>0.981203</td>\n",
       "      <td>{'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518020444</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-4-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.980620</td>\n",
       "      <td>0.995643</td>\n",
       "      <td>0.970428</td>\n",
       "      <td>0.975578</td>\n",
       "      <td>0.981203</td>\n",
       "      <td>{'rows': [{'row': [122.0, 0.0, 0.0]}, {'row': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518020012</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-4-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.980620</td>\n",
       "      <td>0.995643</td>\n",
       "      <td>0.970428</td>\n",
       "      <td>0.975578</td>\n",
       "      <td>0.981203</td>\n",
       "      <td>{'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518010459</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-4-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.992971</td>\n",
       "      <td>0.953692</td>\n",
       "      <td>0.952690</td>\n",
       "      <td>0.952112</td>\n",
       "      <td>{'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518005933</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518005558</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518003709</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518003242</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240518000516</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517232333</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-4-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.996416</td>\n",
       "      <td>0.996838</td>\n",
       "      <td>0.997290</td>\n",
       "      <td>{'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517212539</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'output:metrics-2-metrics': ['projects/102679...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.980652</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517212258</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517211551</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517210244</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517153718</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517152923</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517140100</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517132839</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517122700</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517121120</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240517120242</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516170732</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516165931</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516165036</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516163746</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516162738</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516131326</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516130933</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516130525</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516125735</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516125156</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516124856</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516123429</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240516122852</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>penguins</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240508173548</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>test string</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240508162511</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>test string</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240508140257</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>test string</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pipeline_name                                    run_name  \\\n",
       "0   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518022913   \n",
       "1   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518022407   \n",
       "2   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518021747   \n",
       "3   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518020958   \n",
       "4   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518020753   \n",
       "5   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518020444   \n",
       "6   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518020012   \n",
       "7   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518010459   \n",
       "8   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518005933   \n",
       "9   mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518005558   \n",
       "10  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518003709   \n",
       "11  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518003242   \n",
       "12  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240518000516   \n",
       "13  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517232333   \n",
       "14  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517212539   \n",
       "15  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517212258   \n",
       "16  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517211551   \n",
       "17  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517210244   \n",
       "18  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517153718   \n",
       "19  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517152923   \n",
       "20  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517140100   \n",
       "21  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517132839   \n",
       "22  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517122700   \n",
       "23  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517121120   \n",
       "24  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240517120242   \n",
       "25  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516170732   \n",
       "26  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516165931   \n",
       "27  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516165036   \n",
       "28  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516163746   \n",
       "29  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516162738   \n",
       "30  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516131326   \n",
       "31  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516130933   \n",
       "32  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516130525   \n",
       "33  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516125735   \n",
       "34  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516125156   \n",
       "35  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516124856   \n",
       "36  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516123429   \n",
       "37  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240516122852   \n",
       "38  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240508173548   \n",
       "39  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240508162511   \n",
       "40  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240508140257   \n",
       "\n",
       "                      param.vmlmd_lineage_integration param.input:project_id  \\\n",
       "0   {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "1   {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "2   {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "3   {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "4   {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "5   {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "6   {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "7   {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "8   {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "9   {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "10  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "11  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "12  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "13  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "14  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "15  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "16  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "17  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "18  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "19  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "20  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "21  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "22  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "23  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "24  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "25  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "26  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "27  {'pipeline_run_component': {'parent_task_names...  statmike-mlops-349915   \n",
       "28  {'pipeline_run_component': {'location_id': 'us...  statmike-mlops-349915   \n",
       "29  {'pipeline_run_component': {'parent_task_names...                    NaN   \n",
       "30  {'pipeline_run_component': {'parent_task_names...                    NaN   \n",
       "31  {'pipeline_run_component': {'parent_task_names...                    NaN   \n",
       "32  {'pipeline_run_component': {'location_id': 'us...                    NaN   \n",
       "33  {'pipeline_run_component': {'parent_task_names...                    NaN   \n",
       "34  {'pipeline_run_component': {'parent_task_names...                    NaN   \n",
       "35  {'pipeline_run_component': {'location_id': 'us...                    NaN   \n",
       "36  {'pipeline_run_component': {'parent_task_names...                    NaN   \n",
       "37  {'pipeline_run_component': {'location_id': 'us...                    NaN   \n",
       "38  {'pipeline_run_component': {'parent_task_names...                    NaN   \n",
       "39  {'pipeline_run_component': {'parent_task_names...                    NaN   \n",
       "40  {'pipeline_run_component': {'location_id': 'us...                    NaN   \n",
       "\n",
       "   param.input:bq_table param.input:bq_dataset  \\\n",
       "0              penguins            ml_datasets   \n",
       "1              penguins            ml_datasets   \n",
       "2              penguins            ml_datasets   \n",
       "3              penguins            ml_datasets   \n",
       "4              penguins            ml_datasets   \n",
       "5              penguins            ml_datasets   \n",
       "6              penguins            ml_datasets   \n",
       "7              penguins            ml_datasets   \n",
       "8              penguins            ml_datasets   \n",
       "9              penguins            ml_datasets   \n",
       "10             penguins            ml_datasets   \n",
       "11             penguins            ml_datasets   \n",
       "12             penguins            ml_datasets   \n",
       "13             penguins            ml_datasets   \n",
       "14             penguins            ml_datasets   \n",
       "15             penguins            ml_datasets   \n",
       "16             penguins            ml_datasets   \n",
       "17             penguins            ml_datasets   \n",
       "18             penguins            ml_datasets   \n",
       "19             penguins            ml_datasets   \n",
       "20             penguins            ml_datasets   \n",
       "21             penguins            ml_datasets   \n",
       "22             penguins            ml_datasets   \n",
       "23             penguins            ml_datasets   \n",
       "24             penguins            ml_datasets   \n",
       "25             penguins            ml_datasets   \n",
       "26             penguins            ml_datasets   \n",
       "27             penguins            ml_datasets   \n",
       "28             penguins            ml_datasets   \n",
       "29             penguins            ml_datasets   \n",
       "30             penguins            ml_datasets   \n",
       "31             penguins            ml_datasets   \n",
       "32             penguins            ml_datasets   \n",
       "33             penguins            ml_datasets   \n",
       "34             penguins            ml_datasets   \n",
       "35             penguins            ml_datasets   \n",
       "36             penguins            ml_datasets   \n",
       "37             penguins            ml_datasets   \n",
       "38                  NaN                    NaN   \n",
       "39                  NaN                    NaN   \n",
       "40                  NaN                    NaN   \n",
       "\n",
       "   param.vertex-ai-pipelines-artifact-argument-binding param.input:bq_project  \\\n",
       "0   {'output:metrics-4-metrics': ['projects/102679...    bigquery-public-data   \n",
       "1   {'output:metrics-4-metrics': ['projects/102679...    bigquery-public-data   \n",
       "2   {'output:metrics-4-metrics': ['projects/102679...    bigquery-public-data   \n",
       "3   {'output:metrics-4-metrics': ['projects/102679...    bigquery-public-data   \n",
       "4   {'output:metrics-4-metrics': ['projects/102679...    bigquery-public-data   \n",
       "5   {'output:metrics-4-metrics': ['projects/102679...    bigquery-public-data   \n",
       "6   {'output:metrics-4-metrics': ['projects/102679...    bigquery-public-data   \n",
       "7   {'output:metrics-4-metrics': ['projects/102679...    bigquery-public-data   \n",
       "8                                                 NaN    bigquery-public-data   \n",
       "9                                                 NaN    bigquery-public-data   \n",
       "10                                                NaN    bigquery-public-data   \n",
       "11                                                NaN    bigquery-public-data   \n",
       "12                                                NaN    bigquery-public-data   \n",
       "13  {'output:metrics-4-metrics': ['projects/102679...    bigquery-public-data   \n",
       "14  {'output:metrics-2-metrics': ['projects/102679...    bigquery-public-data   \n",
       "15                                                NaN    bigquery-public-data   \n",
       "16                                                NaN    bigquery-public-data   \n",
       "17                                                NaN    bigquery-public-data   \n",
       "18                                                NaN    bigquery-public-data   \n",
       "19                                                NaN    bigquery-public-data   \n",
       "20                                                NaN    bigquery-public-data   \n",
       "21                                                NaN    bigquery-public-data   \n",
       "22                                                NaN    bigquery-public-data   \n",
       "23                                                NaN    bigquery-public-data   \n",
       "24                                                NaN    bigquery-public-data   \n",
       "25                                                NaN    bigquery-public-data   \n",
       "26                                                NaN    bigquery-public-data   \n",
       "27                                                NaN    bigquery-public-data   \n",
       "28                                                NaN    bigquery-public-data   \n",
       "29                                                NaN    bigquery-public-data   \n",
       "30                                                NaN    bigquery-public-data   \n",
       "31                                                NaN    bigquery-public-data   \n",
       "32                                                NaN    bigquery-public-data   \n",
       "33                                                NaN    bigquery-public-data   \n",
       "34                                                NaN    bigquery-public-data   \n",
       "35                                                NaN    bigquery-public-data   \n",
       "36                                                NaN    bigquery-public-data   \n",
       "37                                                NaN    bigquery-public-data   \n",
       "38                                                NaN                     NaN   \n",
       "39                                                NaN                     NaN   \n",
       "40                                                NaN                     NaN   \n",
       "\n",
       "    metric.accuracy  metric.average_precision  metric.recall  metric.f1  \\\n",
       "0          0.953488                  0.992971       0.953692   0.952690   \n",
       "1          0.980620                  0.995643       0.970428   0.975578   \n",
       "2          0.953488                  0.980936       0.951111   0.952079   \n",
       "3          0.996124                  0.999940       0.996416   0.996838   \n",
       "4          0.980620                  0.995643       0.970428   0.975578   \n",
       "5          0.980620                  0.995643       0.970428   0.975578   \n",
       "6          0.980620                  0.995643       0.970428   0.975578   \n",
       "7          0.953488                  0.992971       0.953692   0.952690   \n",
       "8               NaN                       NaN            NaN        NaN   \n",
       "9               NaN                       NaN            NaN        NaN   \n",
       "10              NaN                       NaN            NaN        NaN   \n",
       "11              NaN                       NaN            NaN        NaN   \n",
       "12              NaN                       NaN            NaN        NaN   \n",
       "13         0.996124                  0.999940       0.996416   0.996838   \n",
       "14         0.953488                  0.980652       0.953488   0.953488   \n",
       "15              NaN                       NaN            NaN        NaN   \n",
       "16              NaN                       NaN            NaN        NaN   \n",
       "17              NaN                       NaN            NaN        NaN   \n",
       "18              NaN                       NaN            NaN        NaN   \n",
       "19              NaN                       NaN            NaN        NaN   \n",
       "20              NaN                       NaN            NaN        NaN   \n",
       "21              NaN                       NaN            NaN        NaN   \n",
       "22              NaN                       NaN            NaN        NaN   \n",
       "23              NaN                       NaN            NaN        NaN   \n",
       "24              NaN                       NaN            NaN        NaN   \n",
       "25              NaN                       NaN            NaN        NaN   \n",
       "26              NaN                       NaN            NaN        NaN   \n",
       "27              NaN                       NaN            NaN        NaN   \n",
       "28              NaN                       NaN            NaN        NaN   \n",
       "29              NaN                       NaN            NaN        NaN   \n",
       "30              NaN                       NaN            NaN        NaN   \n",
       "31              NaN                       NaN            NaN        NaN   \n",
       "32              NaN                       NaN            NaN        NaN   \n",
       "33              NaN                       NaN            NaN        NaN   \n",
       "34              NaN                       NaN            NaN        NaN   \n",
       "35              NaN                       NaN            NaN        NaN   \n",
       "36              NaN                       NaN            NaN        NaN   \n",
       "37              NaN                       NaN            NaN        NaN   \n",
       "38              NaN                       NaN            NaN        NaN   \n",
       "39              NaN                       NaN            NaN        NaN   \n",
       "40              NaN                       NaN            NaN        NaN   \n",
       "\n",
       "    metric.precision                             metric.confusionMatrix  \\\n",
       "0           0.952112  {'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...   \n",
       "1           0.981203  {'rows': [{'row': [122.0, 0.0, 0.0]}, {'row': ...   \n",
       "2           0.953472  {'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...   \n",
       "3           0.997290  {'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...   \n",
       "4           0.981203  {'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...   \n",
       "5           0.981203  {'rows': [{'row': [122.0, 0.0, 0.0]}, {'row': ...   \n",
       "6           0.981203  {'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...   \n",
       "7           0.952112  {'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...   \n",
       "8                NaN                                                NaN   \n",
       "9                NaN                                                NaN   \n",
       "10               NaN                                                NaN   \n",
       "11               NaN                                                NaN   \n",
       "12               NaN                                                NaN   \n",
       "13          0.997290  {'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...   \n",
       "14          0.953488                                                NaN   \n",
       "15               NaN                                                NaN   \n",
       "16               NaN                                                NaN   \n",
       "17               NaN                                                NaN   \n",
       "18               NaN                                                NaN   \n",
       "19               NaN                                                NaN   \n",
       "20               NaN                                                NaN   \n",
       "21               NaN                                                NaN   \n",
       "22               NaN                                                NaN   \n",
       "23               NaN                                                NaN   \n",
       "24               NaN                                                NaN   \n",
       "25               NaN                                                NaN   \n",
       "26               NaN                                                NaN   \n",
       "27               NaN                                                NaN   \n",
       "28               NaN                                                NaN   \n",
       "29               NaN                                                NaN   \n",
       "30               NaN                                                NaN   \n",
       "31               NaN                                                NaN   \n",
       "32               NaN                                                NaN   \n",
       "33               NaN                                                NaN   \n",
       "34               NaN                                                NaN   \n",
       "35               NaN                                                NaN   \n",
       "36               NaN                                                NaN   \n",
       "37               NaN                                                NaN   \n",
       "38               NaN                                                NaN   \n",
       "39               NaN                                                NaN   \n",
       "40               NaN                                                NaN   \n",
       "\n",
       "           param.input:uri param.input:name param.input:a_dict  \n",
       "0                      NaN              NaN                NaN  \n",
       "1                      NaN              NaN                NaN  \n",
       "2                      NaN              NaN                NaN  \n",
       "3                      NaN              NaN                NaN  \n",
       "4                      NaN              NaN                NaN  \n",
       "5                      NaN              NaN                NaN  \n",
       "6                      NaN              NaN                NaN  \n",
       "7                      NaN              NaN                NaN  \n",
       "8                      NaN              NaN                NaN  \n",
       "9                      NaN              NaN                NaN  \n",
       "10                     NaN              NaN                NaN  \n",
       "11                     NaN              NaN                NaN  \n",
       "12                     NaN              NaN                NaN  \n",
       "13                     NaN              NaN                NaN  \n",
       "14                     NaN              NaN                NaN  \n",
       "15                     NaN              NaN                NaN  \n",
       "16                     NaN              NaN                NaN  \n",
       "17                     NaN              NaN                NaN  \n",
       "18                     NaN              NaN                NaN  \n",
       "19                     NaN              NaN                NaN  \n",
       "20                     NaN              NaN                NaN  \n",
       "21                     NaN              NaN                NaN  \n",
       "22                     NaN              NaN                NaN  \n",
       "23                     NaN              NaN                NaN  \n",
       "24                     NaN              NaN                NaN  \n",
       "25                     NaN              NaN                NaN  \n",
       "26                     NaN              NaN                NaN  \n",
       "27                     NaN              NaN                NaN  \n",
       "28                     NaN              NaN                NaN  \n",
       "29                     NaN              NaN                NaN  \n",
       "30                     NaN              NaN                NaN  \n",
       "31                     NaN              NaN                NaN  \n",
       "32                     NaN              NaN                NaN  \n",
       "33                     NaN              NaN                NaN  \n",
       "34                     NaN              NaN                NaN  \n",
       "35                     NaN              NaN                NaN  \n",
       "36                     NaN              NaN                NaN  \n",
       "37                     NaN              NaN                NaN  \n",
       "38  https://www.google.com      test string      {'key': 45.0}  \n",
       "39  https://www.google.com      test string      {'key': 45.0}  \n",
       "40  https://www.google.com      test string      {'key': 45.0}  "
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'{pipeline_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70c004-13f9-472d-a575-f5d3ae6b0911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e13ba6-516f-4a73-85fc-cb6954aa9b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dc537-5166-4122-8cc4-0f51cbc55f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28df188-ddd6-45e3-955d-5346e8562682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac034227-85c8-4305-a1dd-1f6da1267fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77bb31-ae6e-4911-915a-0dac82e7585b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ccf64-776a-47c2-96c2-fd1f2fd320c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199cb4a-fefb-4922-aaa8-df4a9dba5062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aefd22-d8dc-4386-b419-738abd360985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4e70f-088b-4514-af9b-1986ddd4205a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02719a5-9b14-4355-ac5a-b395c428848d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453632dd-750c-4b29-a508-7ab3eab1bbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a2e81-0b3d-4e3f-b191-253608c13154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b461aa74-0526-47a5-8d2a-0537aef8e55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20303c29-2132-4d43-926c-38b78b6f42d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f969fb9-d638-4f49-ae7d-5576b8602a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b47d768a-af53-4f62-b221-8109c810f0bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Artifacts: Vertex AI ML Metadata\n",
    "\n",
    "- https://cloud.google.com/vertex-ai/docs/pipelines/use-components#consume_or_produce_artifacts_in_your_component\n",
    "- https://cloud.google.com/vertex-ai/docs/pipelines/artifact-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0f368-6403-4907-a8e5-cc1d632f61d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b6cd3-b58e-4ede-b622-9175b6ba4b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206b8f0-ac6c-4967-ae66-2cd952c2f8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcce696-2158-48a8-9c25-11b70e1426b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58effcc-bcdf-4a1b-8181-61769a21d85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
