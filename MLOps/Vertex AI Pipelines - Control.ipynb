{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60e5155",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps&file=Vertex+AI+Pipelines+-+Control.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Vertex%20AI%20Pipelines%20-%20Control.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A//raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Vertex%20AI%20Pipelines%20-%20Control.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Vertex%20AI%20Pipelines%20-%20Control.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A//raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Vertex%20AI%20Pipelines%20-%20Control.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e4bfa2-f871-4a91-84a0-c1e4630e4436",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines - Control \n",
    "\n",
    "[Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) is a serverless  runner for Kubeflow Pipelines [(KFP)](https://www.kubeflow.org/docs/components/pipelines/v2/introduction/) and the [TensorFlow Extended (TFX)](ttps://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) framework.\n",
    "\n",
    "Components are used to runs the steps of a pipelines.  A pipeline task runs the component with inputs and results in the components outputs.  The components execute code on compute with a container image.\n",
    "\n",
    "This notebook will focus on controlling the flow of task execution within a pipeline:\n",
    "- **Ordering**: DAG and Explicit ordering\n",
    "- **Conditional Execution**: if, elif (else if), and else\n",
    "    - **Collecting**: Conditional results\n",
    "- **Looping**: And Parallelism\n",
    "    - **Collecting**: Looped Results\n",
    "- **Exit Handling:** with and without task failures\n",
    "- **Error Handling** continue execution even after task failures\n",
    "\n",
    "**References:**\n",
    "- [Kubeflow Pipelines Control Flow](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d7790-dbbf-4d9d-9291-d09d0d826778",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e767408-69f7-45b3-b6e5-da105c4b2519",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e75c429-7a0e-48d7-aa78-64d82a73a864",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5249b0-69ab-470f-8c02-5d277cefe1fa",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c58f135-2b70-4814-b8e2-4ef3ca37fab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('kfp', 'kfp')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d1fb44-5f69-40a7-b627-0374c6db6eb4",
   "metadata": {},
   "source": [
    "## API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1f5860-3efc-4632-b4c0-ba5b262dec12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e5ca2-6d31-4b73-8db2-ac75b7670be4",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecee10aa-99b0-4daa-8fb2-38e5646af9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe566058-b390-484e-980b-d03640d02e77",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7364b-699b-4c26-a617-0dbbd9e4c51d",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3553bc6-67f5-44bb-a16c-9f43cee51546",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce46c83-6305-4210-adb9-674047137832",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'pipeline-control'\n",
    "SERIES = 'mlops'\n",
    "\n",
    "# gcs bucket\n",
    "GCS_BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd21676-844f-441f-9dc6-db15dddf9ed2",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86cf0800-eb89-4c49-b20e-e752698f501a",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import importlib\n",
    "from google.cloud import aiplatform\n",
    "import kfp\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3b756-c6b3-4c0c-9dfb-19a9f2e08388",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b9f0e32-9d71-40ed-bd02-cf8fdfd04863",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59e086-017e-42c8-a19d-67c6eac8687d",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d59e937-5c05-4fc2-9e25-b96937dbd2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"temp/{SERIES}-{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d1eb622-626e-433a-9021-51655e893db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a42dc-aa9d-4cc9-824c-a708079a7ad5",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18bb246b-2641-4d56-a3c2-40b355197590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd167d8-e15d-46d7-9852-da95c687c390",
   "metadata": {},
   "source": [
    "---\n",
    "## Example Components\n",
    "\n",
    "Components that:\n",
    "- generate coin flips with `flip_coin`\n",
    "    - by default it returns flip of a single coin as 'H' or 'T'\n",
    "    - optional input parameter of `num_coins` can be set to number of coins to retrive a string of flips, like 2 => 'HT'\n",
    "- generate dice rolls with `roll_dice`\n",
    "    - by default it returns the face number [1, 6] from a single die roll\n",
    "    - optionn input parameter of `num_dice` an be set to number of dice to retrieve a sum of rolls, like 2 => [2, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "95cd7aaa-9c63-4ccd-bdb2-84b1fa39acfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def flip_coins(num_coins: int = 1) -> str:\n",
    "    import random\n",
    "    flipmap = ['T', 'H']\n",
    "    flips = [flipmap[random.randint(0, 1)] for n in range(num_coins)]\n",
    "    return ''.join(flips)\n",
    "\n",
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def roll_dice(num_dice: int = 1) -> int:\n",
    "    import random\n",
    "    result = sum([random.randint(1,6) for n in range(num_dice)])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d79fb-e6ae-4fda-8111-847cbbb90010",
   "metadata": {},
   "source": [
    "---\n",
    "## Function To Run Pipeline\n",
    "\n",
    "A helper function that will compile a KFP pipeline, create a Vertex AI Pipeline job, submit and wait on the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e0c27612-72fa-49f5-a7b5-ab15abfa9318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pipeline_runner(pipeline_func, pipeline_name):\n",
    "    \n",
    "    # compile the pipeline\n",
    "    kfp.compiler.Compiler().compile(\n",
    "        pipeline_func = pipeline_func,\n",
    "        package_path = f'{DIR}/{pipeline_name}.yaml'\n",
    "    )\n",
    "    \n",
    "    # create pipeline job\n",
    "    pipeline_job = aiplatform.PipelineJob(\n",
    "        display_name = f\"{pipeline_name}\",\n",
    "        template_path = f\"{DIR}/{pipeline_name}.yaml\",\n",
    "        pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    )\n",
    "    \n",
    "    # submit pipeline job\n",
    "    response = pipeline_job.submit(\n",
    "        service_account = SERVICE_ACCOUNT\n",
    "    )\n",
    "    \n",
    "    # wait on pipeline job\n",
    "    pipeline_job.wait()\n",
    "    \n",
    "    # return pipeline job\n",
    "    return pipeline_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6b8d7-d74a-4e97-a9aa-f59a42e46046",
   "metadata": {},
   "source": [
    "---\n",
    "## Ordering Tasks: DAG\n",
    "\n",
    "The outputs of components are used as inputs to other components forcing an order of operations - a [DAG (directed acyclic graph)](https://en.wikipedia.org/wiki/Directed_acyclic_graph).  All of the `task_1*` tasks run at the same time as they have no dependencies.  Then, each of the `task_2*` tasks run after their corresponding `task_1*` task completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f553f6ec-24b8-4b48-9191-d400dc78108c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "390a21cf-bc2c-4238-9e6b-6f95fda883b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag():\n",
    "    \n",
    "    task_1a = roll_dice()\n",
    "    task_1b = roll_dice(num_dice = 2)\n",
    "    task_1c = roll_dice(num_dice = 3)\n",
    "    \n",
    "    task_2a = flip_coins(num_coins = task_1a.output)\n",
    "    task_2b = flip_coins(num_coins = task_1b.output)\n",
    "    task_2c = flip_coins(num_coins = task_1c.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2fdcef04-91ea-4a6f-b870-58854a821a18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20240327152838\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20240327152838')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-20240327152838?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20240327152838 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20240327152838 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20240327152838 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20240327152838 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20240327152838 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-20240327152838\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "072e238a-7a2e-4d57-b264-d1b76b97bf90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-20240327152838?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72913a-643e-476f-8b14-41f0bd043bb8",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG\" src=\"../architectures/notebooks/mlops/order-dag.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6f58f-f9c3-47e9-b71d-124bf96e1a32",
   "metadata": {},
   "source": [
    "---\n",
    "## Ordering Tasks: DAG + Explicit Dependency\n",
    "\n",
    "The outputs of components are used as inputs to other components forcing an order of operations. \n",
    "\n",
    "The `task_1*` component do not have any input dependencies and by default run at the same time - as seen above.  Using the `.after()` method - [reference](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.PipelineTask.after) - allows for explicit dependency on another task.  The pipeline below uses `.after()` to force the order of the `task_1a`, then `task_1b`, then `task_1c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "98e18c9c-398c-4198-9aa9-82e9fa747080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-explicit'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-explicit\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "248585be-df52-437e-93af-98aa98055cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_explicit():\n",
    "\n",
    "    task_1a = roll_dice()\n",
    "    task_1b = roll_dice(num_dice = 2).after(task_1a)\n",
    "    task_1c = roll_dice(num_dice = 3).after(task_1b)\n",
    "    \n",
    "    task_2a = flip_coins(num_coins = task_1a.output)\n",
    "    task_2b = flip_coins(num_coins = task_1b.output)\n",
    "    task_2c = flip_coins(num_coins = task_1c.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "92d9552c-8334-4464-81ec-87d755727d79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20240327153538\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20240327153538')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-explicit-20240327153538?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20240327153538 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20240327153538 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20240327153538 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20240327153538 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-explicit-20240327153538\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_explicit, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5aeb13c2-e176-48e4-9591-2894db4c3890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-explicit-20240327153538?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db14f569-eef5-407f-b547-08c1b6081916",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Explicit\" src=\"../architectures/notebooks/mlops/order-dag-explicit.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfede210-2358-4fa4-8547-cef3c720b432",
   "metadata": {},
   "source": [
    "---\n",
    "## Conditional Execution\n",
    "\n",
    "Sometimes, the execution of a component depends on an output value from another component.  Rather than need to build the logic into a component, there are `dsl` methods for evaluating task outputs:\n",
    "- `kfp.dsl.If`\n",
    "- `kfp.dsl.Elif`\n",
    "- `kfp.dsl.Else`\n",
    "\n",
    "[Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#conditions-dslif-dslelif-dslelse)\n",
    "\n",
    "\n",
    "In the example pipeline below the same three task that convert numbers to letter are used.  Then new tasks are used to flip a coin and roll a single die. If the coin is heads, the result of die is used to conditionally convert one of the three letters back to a number.  If the coin is tails then all three letters are converted back to numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5c874851-fdb2-4d8c-ae00-28e838db954d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-condition'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-condition\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bb110727-4e4b-4d42-9f47-114c653daded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_condition():\n",
    "\n",
    "    task_1a = roll_dice()\n",
    "    task_1b = roll_dice(num_dice = 2)\n",
    "    task_1c = roll_dice(num_dice = 3)\n",
    "    task_1d = roll_dice(num_dice = 4)\n",
    "\n",
    "    coin = flip_coins() \n",
    "    with kfp.dsl.If(coin.output == \"H\", name = 'Flip: Heads (H)'):\n",
    "        \n",
    "        die = roll_dice()\n",
    "        with kfp.dsl.If(die.output <= 2, name = 'Roll: 1, 2'):\n",
    "            task_2a = flip_coins(num_coins = task_1a.output)\n",
    "        with kfp.dsl.Elif(die.output <= 4, name = 'Roll: 3, 4'):\n",
    "            task_2b = flip_coins(num_coins = task_1b.output)\n",
    "        with kfp.dsl.Else(name = 'Roll: 5, 6'):\n",
    "            task_2c = flip_coins(num_coins = task_1c.output)\n",
    "\n",
    "    with kfp.dsl.Elif(coin.output == \"T\", name = 'Flip: Tails (T)'):\n",
    "        task_2d = flip_coins(num_coins = task_1d.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c5e9653d-093c-4bdc-bb08-2184e1fac1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20240327155436\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20240327155436')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-condition-20240327155436?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20240327155436 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20240327155436 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20240327155436 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20240327155436 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-20240327155436\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_condition, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e57788eb-352e-4a69-abc7-7a1f1e709049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-condition-20240327155436?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798edb0a-6bda-47f9-8d96-62e8850eb607",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Conditions\" src=\"../architectures/notebooks/mlops/order-dag-condition.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e291219-b9ce-4357-aa99-2afd98e04f88",
   "metadata": {},
   "source": [
    "---\n",
    "### Conditional Execution: Collecting Tasks\n",
    "\n",
    "In the previous section, conditional exeuction with `kfp.dsl.If()`, `kfp.dsl.Elif()`, `kfp.dsl.Else()` was used.  If a downstream task needs to use the result of any tasks that ends up executing then it needs to monitor all the possibilities.  This is where\n",
    "`kfp.dsl.OneOf()` comes in handy. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#dsloneof)\n",
    "\n",
    "The following pipeline repeats the flow from above and adds the `kfp.dsl.OneOf()` to collect all the conditional tasks: `task_2*`.  A new component is created that will take as input this collected result and calculate the frequency of outcomes 'H' and 'T'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e49b082f-44f0-4097-aad1-e86909eebbae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def coin_freq(flips: str) -> dict:\n",
    "    result = dict(\n",
    "        H = flips.count('H'),\n",
    "        T = flips.count('T')\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "84f8ad06-da5d-4060-a534-c1d702f196ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-condition-collect'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-condition-collect\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4ba4e08f-d0b0-4a0e-934d-c4d4911ec391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_condition_collect():\n",
    "\n",
    "    task_1a = roll_dice()\n",
    "    task_1b = roll_dice(num_dice = 2)\n",
    "    task_1c = roll_dice(num_dice = 3)\n",
    "    task_1d = roll_dice(num_dice = 4)\n",
    "\n",
    "    coin = flip_coins() \n",
    "    with kfp.dsl.If(coin.output == \"H\", name = 'Flip: Heads (H)'):\n",
    "        \n",
    "        die = roll_dice()\n",
    "        with kfp.dsl.If(die.output <= 2, name = 'Roll: 1, 2'):\n",
    "            task_2a = flip_coins(num_coins = task_1a.output)\n",
    "        with kfp.dsl.Elif(die.output <= 4, name = 'Roll: 3, 4'):\n",
    "            task_2b = flip_coins(num_coins = task_1b.output)\n",
    "        with kfp.dsl.Else(name = 'Roll: 5, 6'):\n",
    "            task_2c = flip_coins(num_coins = task_1c.output)\n",
    "\n",
    "        oneof = kfp.dsl.OneOf(task_2a.output, task_2b.output, task_2c.output)\n",
    "        coin_freq(flips = oneof)\n",
    "            \n",
    "    with kfp.dsl.Elif(coin.output == \"T\", name = 'Flip: Tails (T)'):\n",
    "        task_2d = flip_coins(num_coins = task_1d.output)\n",
    "        coin_freq(flips = task_2d.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fe4e4aec-b0ea-4a7c-92ef-c83a9b7c384c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20240327161739\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20240327161739')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-condition-collect-20240327161739?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20240327161739 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20240327161739 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20240327161739 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20240327161739 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-condition-collect-20240327161739\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_condition_collect, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4f3f62a6-c494-4824-a929-f14ac2b24e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-condition-collect-20240327161739?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f8fcb-06f6-4565-9ff2-1cf7fc4365a1",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Condition - Collect\" src=\"../architectures/notebooks/mlops/order-dag-condition-collect.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1c34e-6ce7-429e-b333-4b735fb9cb37",
   "metadata": {},
   "source": [
    "---\n",
    "## Looping - And Parallelism\n",
    "\n",
    "With KFP the same task can be repeated, or looped, for multiple input values.  This is done with `kfp.dsl.ParallelFor`.  With a list of values to iterate over this will run the task for each item in the list.  An item can also be a dictionary making it possible to provide multiple input parameters for each iteration.  As the name implies, the iterations are actually conducted in parallel.  The level of parallelism is set to maximum by default but can also be directly controlled with the `parallelism` parameter. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/)\n",
    "\n",
    "The example below conducts a `kfp.dsl.ParallelFor()` loop over a list of integers [1, 10].  For each value the `roll_dice` component is runs as a task with the integer used as the input number of dice to roll and sum.  This creates 10 tasks, each with a different number of dice to roll and sum.  The `parallelism = 5` setting is used to show how it will limit the number of simoultaneous tasks executions to 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3d7d13a5-064f-4718-b3d7-f3bc5feb9051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-looping'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-looping\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5441e15f-b95a-4d4d-95dc-40536cf3ff6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_looping():\n",
    "    \n",
    "    with kfp.dsl.ParallelFor(\n",
    "        items = list(range(1, 11)),\n",
    "        parallelism = 5,\n",
    "        name = 'Loop of 10, 5 at a time'\n",
    "    ) as num_dice:\n",
    "        roll_dice(num_dice = num_dice).set_display_name(f'Sum of Die')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3839de10-b2ba-4438-848d-0c13adeed588",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20240327162234\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20240327162234')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-looping-20240327162234?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20240327162234 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20240327162234 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20240327162234 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20240327162234 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-20240327162234\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_looping, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8b70e3a9-45db-4f3e-b385-232d95c3955d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-looping-20240327162234?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3850558-50fa-4772-b0f4-770ff221549b",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Looping (running)\" src=\"../architectures/notebooks/mlops/order-dag-looping1.png\" width=\"45%\">\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    &nbsp;\n",
    "    <img alt=\"Order DAG - Looping (done)\" src=\"../architectures/notebooks/mlops/order-dag-looping2.png\" width=\"45%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fde032-492a-48f1-b07a-eedf645ed426",
   "metadata": {},
   "source": [
    "---\n",
    "### Looping: Collecting Tasks\n",
    "\n",
    "In the previous section, looping with `kfp.dsl.ParallelFor()` was used.  If a downstream task needs to use the results of each loop iteration then it is necessary to wait and collect the results.  This is where\n",
    "`kfp.dsl.Collected()` comes in handy. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#dslcollected)\n",
    "\n",
    "\n",
    "The pipeline is updated to add a new component, `sum_number()`, which will take the results of `kfp.dsl.Collected` as an input.  In this case, the collection is the output of each `roll_dice` tasks which is a list of numbers that each represent the sum of the dice rolled in the individual iterations task.  Now, the sum of all these `roll_dice` task outputs is created by the new `sum_numbers` component based task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8aeee680-f738-4696-98d3-6a44e4fc2640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def sum_numbers(numbers: list) -> int:\n",
    "    result = sum(numbers)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e82a7666-2c97-4073-9873-c77f753fe53f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-looping-collect'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-looping-collect\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dca64e31-8023-412e-ba70-f052d018a7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_looping_collect():\n",
    "    \n",
    "    with kfp.dsl.ParallelFor(\n",
    "        items = list(range(1, 11)),\n",
    "        parallelism = 5,\n",
    "        name = 'Loop of 10, 5 at a time'\n",
    "    ) as num_dice:\n",
    "        sum_roll = roll_dice(num_dice = num_dice).set_display_name(f'Sum of Die')\n",
    "        \n",
    "    sum_numbers(numbers = kfp.dsl.Collected(sum_roll.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "917768a7-ba8a-4975-8146-e07174f6e7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20240327162948\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20240327162948')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-looping-collect-20240327162948?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20240327162948 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20240327162948 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20240327162948 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20240327162948 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-looping-collect-20240327162948\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_looping_collect, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3e7adc01-deb0-4159-91c8-1c9559c1ce20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-looping-collect-20240327162948?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3e747-8167-4f02-a012-8d1eb32e606e",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Looping - Collect\" src=\"../architectures/notebooks/mlops/order-dag-looping-collect.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9d5ba-41c2-45ed-a945-e0226136b887",
   "metadata": {},
   "source": [
    "---\n",
    "## Exit Handling\n",
    "\n",
    "When a tasks or group of task needs to be followed by specific actions the `kfp.dsl.ExistHandler` will help.  This allows setting a specific tasks as an exit task so that after that tasks finishes (or fails) additional task will run. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#exit-handling-dslexithandler)\n",
    "\n",
    "\n",
    "The pipeline below runs three task with the `roll_dice` component.  The `kfp.dsl.ExitHandler` runs task 'task_2a' after 'task_1c' is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d6ce0e3e-62eb-45fd-89e0-1c7e6aa97b62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-exithandle'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-exithandle\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b70e5f9b-c930-4bee-8d4b-5a0220bd17f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_exithandle():\n",
    " \n",
    "    task_2a = flip_coins(num_coins = 10)\n",
    "    \n",
    "    with kfp.dsl.ExitHandler(exit_task = task_2a, name = 'After Dice Roll Tasks, flip coins'):   \n",
    "        task_1a = roll_dice()\n",
    "        task_1b = roll_dice(num_dice = 2).after(task_1a)\n",
    "        task_1c = roll_dice(num_dice = 3).after(task_1b)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4cff54b8-d677-4964-96d8-84eefb0ff483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20240327171309\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20240327171309')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-20240327171309?project=1026793852137\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-20240327171309\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_exithandle, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "72751e1e-c363-4bea-bb0b-5957cbc097ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-20240327171309?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab73d3-bbfd-45d4-83d3-3e28aa4dec71",
   "metadata": {},
   "source": [
    "<p><center>\n",
    "    <img alt=\"Order DAG - Exit Handle\" src=\"../architectures/notebooks/mlops/order-dag-exithandle.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7eabe2-65d5-4176-8bef-ddf9bdb39e64",
   "metadata": {},
   "source": [
    "### Exit Handling: With Failures\n",
    "\n",
    "A type of exit is an error.  The following pipeline alters the pipeline above by adding a component that forces an error.  This shows that the `kfp.dsl.ExitHandler` still executes its `exit_task` after the failure.\n",
    "\n",
    "**Notice**: The pipeline does fail!  But the `exit_task` still completes after the failure.  The downstream task from the failure does not commence though.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2b4b1933-373f-4e8b-9448-f8dab8f4f38a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(base_image = 'python:3.10')\n",
    "def force_fail():\n",
    "    import sys\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d3e6173d-64c3-4717-9000-7a45642228fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-exithandle-failure'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-exithandle-failure\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "880655c2-bf44-4222-a331-30d3bd1a5ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_exithandle_failure():\n",
    " \n",
    "    task_2a = flip_coins(num_coins = 10)\n",
    "    \n",
    "    with kfp.dsl.ExitHandler(exit_task = task_2a, name = 'After Dice Roll Tasks, flip coins'):   \n",
    "        task_1a = roll_dice()\n",
    "        task_1b = roll_dice(num_dice = 2).after(task_1a)\n",
    "        task_fail = force_fail().after(task_1b)\n",
    "        task_1c = roll_dice(num_dice = 3).after(task_fail)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8d228b3c-27cf-4930-b7f4-34ce1a022f89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20240327172344\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20240327172344')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-failure-20240327172344?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20240327172344 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20240327172344 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20240327172344 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-exithandle-failure-20240327172344 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [exit-handler-1].; Job (project_id = statmike-mlops-349915, job_id = 7035289196877053952) is failed due to the above error.; Failed to handle the job: {project_number = 1026793852137, job_id = 7035289196877053952}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[169], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipeline_job \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_pipeline_dag_exithandle_failure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[105], line 22\u001b[0m, in \u001b[0;36mpipeline_runner\u001b[0;34m(pipeline_func, pipeline_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_job\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m     18\u001b[0m     service_account \u001b[38;5;241m=\u001b[39m SERVICE_ACCOUNT\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# wait on pipeline job\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mpipeline_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# return pipeline job\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline_job\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:550\u001b[0m, in \u001b[0;36mPipelineJob.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for this PipelineJob to complete.\"\"\"\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_latest_future \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mwait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:615\u001b[0m, in \u001b[0;36mPipelineJob._block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Error is only populated when the job state is\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;129;01min\u001b[39;00m _PIPELINE_ERROR_STATES:\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob failed with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39merror)\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [exit-handler-1].; Job (project_id = statmike-mlops-349915, job_id = 7035289196877053952) is failed due to the above error.; Failed to handle the job: {project_number = 1026793852137, job_id = 7035289196877053952}\"\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_exithandle_failure, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e00ecab9-159f-4f42-89fb-c1b98e15ea69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-20240327172303?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce67c9b-ebe8-493c-b0c6-a44f3f0e9655",
   "metadata": {},
   "source": [
    "**Notice**: The pipeline does fail!  But the `exit_task` still completes after the failure.  The downstream task from the failure does not commence though.  \n",
    "\n",
    "<p><center>\n",
    "    <img alt=\"Order DAG - Exit Handle\" src=\"../architectures/notebooks/mlops/order-dag-exithandle-failure.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc18659-9da0-411d-8a10-10baeb5bdc97",
   "metadata": {},
   "source": [
    "---\n",
    "## Error Handling\n",
    "\n",
    "The example above shows how the `kfp.dsl.ExitHandler` can continue with an `exit_task` even after a failure.  There are times where tasks still can be run even when an upstream task failed.  Like the 'task_1c' in that prior pipeline which has no inputs from the failed task, it just happens to be run after the task.  For this, the `.ignore_upstream_failure()` task method is a great solution. [Reference](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/#ignore-upstream-failure)\n",
    "\n",
    "The prior pipeline is updated with the `.ignotre_upstream_failure()` method added to 'task_1c'.\n",
    "\n",
    "**Notice**: As before, the pipeline fails and `exit_task` still completes after the failure.  This time, the downstream task from the failure does continue and complete successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "badba070-f74e-4212-8a6b-1bd0a99abf39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlops-pipeline-control-order-dag-errorhandle'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{SERIES}-{EXPERIMENT}-order-dag-errorhandle\"\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dddd6dd5-c43e-4f2a-8aa4-5e2923c6e5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = pipeline_name)\n",
    "def order_pipeline_dag_errorhandle():\n",
    " \n",
    "    task_2a = flip_coins(num_coins = 10)\n",
    "    \n",
    "    with kfp.dsl.ExitHandler(exit_task = task_2a, name = 'After Dice Roll Tasks, flip coins'):   \n",
    "        task_1a = roll_dice()\n",
    "        task_1b = roll_dice(num_dice = 2).after(task_1a)\n",
    "        task_fail = force_fail().after(task_1b)\n",
    "        task_1c = roll_dice(num_dice = 3).after(task_fail).ignore_upstream_failure()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9159506a-7e63-48db-ab26-830ff132f34b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20240327184805\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20240327184805')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-errorhandle-20240327184805?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20240327184805 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20240327184805 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20240327184805 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20240327184805 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20240327184805 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-control-order-dag-errorhandle-20240327184805 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [exit-handler-1].; Job (project_id = statmike-mlops-349915, job_id = 1551030750646632448) is failed due to the above error.; Failed to handle the job: {project_number = 1026793852137, job_id = 1551030750646632448}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipeline_job \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_pipeline_dag_errorhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[105], line 22\u001b[0m, in \u001b[0;36mpipeline_runner\u001b[0;34m(pipeline_func, pipeline_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_job\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m     18\u001b[0m     service_account \u001b[38;5;241m=\u001b[39m SERVICE_ACCOUNT\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# wait on pipeline job\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mpipeline_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# return pipeline job\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline_job\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:550\u001b[0m, in \u001b[0;36mPipelineJob.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for this PipelineJob to complete.\"\"\"\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_latest_future \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mwait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:615\u001b[0m, in \u001b[0;36mPipelineJob._block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Error is only populated when the job state is\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;129;01min\u001b[39;00m _PIPELINE_ERROR_STATES:\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob failed with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39merror)\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [exit-handler-1].; Job (project_id = statmike-mlops-349915, job_id = 1551030750646632448) is failed due to the above error.; Failed to handle the job: {project_number = 1026793852137, job_id = 1551030750646632448}\"\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = pipeline_runner(order_pipeline_dag_errorhandle, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8f9a4a38-a8ea-40e0-a53c-b0ba6eeb5bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-control-order-dag-exithandle-20240327172303?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663c602-3ea6-4d37-b50f-e48c870de637",
   "metadata": {},
   "source": [
    "**Notice**: As before, the pipeline fails and `exit_task` still completes after the failure.  This time, the downstream task from the failure does continue and complete successfully.\n",
    "<p><center>\n",
    "    <img alt=\"Order DAG - Exit Handle\" src=\"../architectures/notebooks/mlops/order-dag-errorhandle.png\" width=\"90%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e8b76-6e01-44d2-ba8d-8a2bc603415e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
