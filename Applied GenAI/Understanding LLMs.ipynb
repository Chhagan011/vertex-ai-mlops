{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f61b14",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI&file=Understanding+LLMs.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Understanding%20LLMs.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FUnderstanding%2520LLMs.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Understanding%20LLMs.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Understanding%20LLMs.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e408ff-907f-4ef5-ae6a-37c755bc26d4",
   "metadata": {},
   "source": [
    "# Understanding LLMs\n",
    "\n",
    "A quick experiment to illustrate what an LLM is actually doing\n",
    "\n",
    "Take a well known passage of text, like the first paragraph from \"A Tale of Two Cities\" by Charles Dickens and Harvy Dunn, 1921:\n",
    "\n",
    ">It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\n",
    "\n",
    "Imagine you are the author and have started writing this paragraph.  How likely is it to end up with these words?\n",
    "\n",
    "You start with 'It'.  That narrows down what comes next.  Given all of the text samples an LLM is trained on we can detect the most likely next word and it is 'was'.  \n",
    "Now start with 'It was'.  What comes next?\n",
    "\n",
    "How long before we start with enough that the LLM can actually decide the mostly likely continuation is the exact same passage?  After just 5 words the LLM can recite the remainder of the paragrph as the sequence is that unique!\n",
    "\n",
    "Since the LLM was trained on a large amount of text that most certainly contained this very popular book that is also in the [public domain](https://www.loc.gov/item/05000749/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680587e-b7ff-4745-8ae8-25ed8274ffb4",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Understanding%20LLMs.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcad757-568c-40fb-8cf6-200969971337",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d35703-a49e-4663-b2be-4c6d0a412aee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329bf643-d031-4eca-9231-08e903d501bf",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1400e0e-d4f3-46bd-afef-5785e047339b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f6269-8099-4c3b-8282-797f5b3cc34f",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390bb3dd-8a57-46eb-9a70-84cc62ad20ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c313391-c3fa-41b1-80ca-d7bbd653adcb",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d420e6bb-c0e5-42f9-a777-7e32ac7a9719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33ebd4-be60-4812-af0b-00f295af62d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf698e18-fede-457f-8f85-3dfe004d55b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f980027-e473-4cab-9cdf-96159cf4cf52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6db806-6298-4b82-bb51-3821420cc246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import vertexai.language_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40fc646-06da-4592-897e-b5a1a2730cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e96ca4-5383-47e1-ad12-1fe39bd1a4a7",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup LLM and Predictor Function\n",
    "\n",
    "Connect to the `text-bison` model for text generation.  Then build a helper function around the LLM prediction calls to:\n",
    "- specify how many input words from the known `sample` to pass as input\n",
    "- specify how many output words to ask for\n",
    "- specify how many tries/request to make for output words\n",
    "    - adjust temperature from 0 to 0.1 to see more than just the most likely next word chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a070b10-490f-4ab0-a2f9-124a85a962fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = vertexai.language_models.TextGenerationModel.from_pretrained('text-bison@001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d14262ae-477e-46fd-a6a6-e4ba5fcd71e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\n"
     ]
    }
   ],
   "source": [
    "sample = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\"\n",
    "spaces = [i for i, char in enumerate(sample) if char == ' ']\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b81a4b0-b52e-4b0a-b180-ad7be311ddd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predictor(words, new_words, trys = 1):\n",
    "    start = sample[0:spaces[words-1]]\n",
    "    print('The input is: ', start)\n",
    "    print('Correct Next: ', sample[spaces[words-1]:spaces[words+new_words-1]])\n",
    "    temperature = 0\n",
    "    \n",
    "    max_output_tokens = new_words\n",
    "    top_k = trys\n",
    "    if trys > 1: temperature = 0.1\n",
    "    top_p = 1\n",
    "\n",
    "    if trys == 1: print('Response: ', llm.predict(start, temperature = temperature, max_output_tokens = max_output_tokens, top_k = top_k, top_p = top_p).text)\n",
    "    else:\n",
    "        for i in range(trys):\n",
    "            print(f'Response {i+1}', llm.predict(start, temperature = temperature, max_output_tokens = max_output_tokens, top_k = top_k, top_p = top_p).text)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c709556c-585f-4fd0-95a2-e2b30b52abc8",
   "metadata": {},
   "source": [
    "---\n",
    "## Predict the Next Word(s)...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bfb5ac-c0b3-48fe-a43f-2a4cd2a19ebe",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 1 word out, try 1 time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5576c7b4-e9ca-4037-b741-2fdf3f06f5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the\n",
      "Correct Next:   worst\n",
      "Response:  \n"
     ]
    }
   ],
   "source": [
    "predictor(1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0aefec-c8f0-4553-9097-b8ffd1e13ce0",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 2 words out, try 1 time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fe4f8e3-750e-4a4b-81f8-40585b7b1d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the\n",
      "Correct Next:   worst of\n",
      "Response:  \n"
     ]
    }
   ],
   "source": [
    "predictor(1, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ccf17-7ccf-4195-a6bb-01bc7edc33e6",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 2 words out, try 10 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be323173-4660-4584-91c8-2f6055842495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the\n",
      "Correct Next:   worst of\n",
      "Response 1 \n",
      "Response 2 \n",
      "Response 3 \n",
      "Response 4 \n",
      "Response 5 \n",
      "Response 6 \n",
      "Response 7 \n",
      "Response 8 \n",
      "Response 9 \n",
      "Response 10 \n"
     ]
    }
   ],
   "source": [
    "predictor(1, 2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9b171-5499-4713-b12d-d4e1bf1f99bf",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 3 words out, try 1 time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "856c0f03-8822-4103-95ac-70ef482b9085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the\n",
      "Correct Next:   worst of times,\n",
      "Response:  \n"
     ]
    }
   ],
   "source": [
    "predictor(1, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694311a-eb8c-432d-830a-f3836f7bd9a6",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 3 words out, try 10 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "29ac4659-b67f-4770-a634-cae7e2c27a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the\n",
      "Correct Next:   worst of times,\n",
      "Response 1 \n",
      "Response 2 \n",
      "Response 3 \n",
      "Response 4 \n",
      "Response 5 \n",
      "Response 6 \n",
      "Response 7 \n",
      "Response 8 \n",
      "Response 9 \n",
      "Response 10 \n"
     ]
    }
   ],
   "source": [
    "predictor(1, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2df9a2-d1ab-4d5f-a099-518b39878ce0",
   "metadata": {},
   "source": [
    "## How Many Input Words Are Needed To Correctly Reproduce The Sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd96057-b4fb-409f-9f18-acccc5faddcb",
   "metadata": {},
   "source": [
    "Pass 2 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74745993-17f6-4962-a2b2-9f0492d97b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst\n",
      "Correct Next:   of\n",
      "Response:  .\n"
     ]
    }
   ],
   "source": [
    "predictor(2, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c0d66-e397-4efa-bb85-b848124aa69a",
   "metadata": {},
   "source": [
    "Pass 3 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "346ba61a-c241-41f7-bd41-621d0c9d2445",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of\n",
      "Correct Next:   times,\n",
      "Response:  the\n"
     ]
    }
   ],
   "source": [
    "predictor(3, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a6d30-d1aa-4528-a7ce-3635de5d3526",
   "metadata": {},
   "source": [
    "Pass 4 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6cf054e7-ece0-4be3-b6af-91b25044a22b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times,\n",
      "Correct Next:   it\n",
      "Response:  the\n"
     ]
    }
   ],
   "source": [
    "predictor(4, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5ddf6-bc94-4c36-8375-d18ca43ea026",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 1 word out, try 1 time: answer is CORRECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5aac306c-8473-45c2-95ea-181a3a0fca03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it\n",
      "Correct Next:   was\n",
      "Response:  is\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e26bf-44e2-4af4-ba2d-bade1fcb94f9",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 4 words out, try 1 time: answer is CORRECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe4403e3-59d2-44aa-a907-6f41ab33cfd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it\n",
      "Correct Next:   was the age of\n",
      "Response:  is important to remember\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5be41-56d9-4204-b0e5-719ee1c1cd4d",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 20 words out, try 1 time: answer is CORRECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ece54493-9880-41d7-8eea-967fd52599bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it\n",
      "Correct Next:   was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the\n",
      "Response:  is important to remember that there are always people who care about you and want to help. If you\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 20, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a323708-5602-4816-982a-bdbe9f50b5b9",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 20 words out, try 5 time: answer is CORRECT consistantly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f009ad3e-d527-49c6-82a8-baba8155367d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it\n",
      "Correct Next:   was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the\n",
      "Response 1 's important to remember that there are still good people in the world.\n",
      "Response 2 's important to remember that there are always people who care about you and want to help. If\n",
      "Response 3 's important to remember that there are always people who care about you. If you're feeling\n",
      "Response 4 's important to remember that there are always people who care about you. If you're feeling\n",
      "Response 5 is important to remember that there are always people who care about you and want to help. If you\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8da6dc-4ed3-42a3-97c2-8c3b677c5756",
   "metadata": {},
   "source": [
    "## Starting Mid-Sentence, How Many Input Words Are Needed To Correctly Reproduce The Sample?\n",
    "\n",
    "Following the same process as above, but starting inside the first sentence.\n",
    "\n",
    "After 6, 8, and 9 words it guesses the next word correctly but cannot guess the remainder of the passage.\n",
    "\n",
    "After 10 words it is then able to deduce the remainder of the passage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abcddabc-4631-45ae-9208-07fba13a61aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = \"the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\"\n",
    "spaces = [i for i, char in enumerate(sample) if char == ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aef689-dc3f-471d-bcec-a854b570f32c",
   "metadata": {},
   "source": [
    "Pass 2 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fadf4aa3-266f-41da-a240-6e61cb832bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst\n",
      "Correct Next:   of\n",
      "Response:  .\n"
     ]
    }
   ],
   "source": [
    "predictor(2, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82ee1d0-f55e-45fe-92f5-bd94e4b66747",
   "metadata": {},
   "source": [
    "Pass 3 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de042176-bbe9-4d06-b9a7-ed68cdacaff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of\n",
      "Correct Next:   times,\n",
      "Response:  the\n"
     ]
    }
   ],
   "source": [
    "predictor(3, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12695b97-b123-4a5c-b623-8e845c7cd9fb",
   "metadata": {},
   "source": [
    "Pass 4 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "65af2b7f-ef36-4687-b1ac-a1573f4ee5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times,\n",
      "Correct Next:   it\n",
      "Response:  the\n"
     ]
    }
   ],
   "source": [
    "predictor(4, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf571e54-2695-40fb-bb10-0a0d88dce54c",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1edd89c7-a7c8-4bc1-8d4c-bfe33e12b0e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it\n",
      "Correct Next:   was\n",
      "Response:  is\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a41c97-0eea-41dd-b9d7-6bd810b3fe53",
   "metadata": {},
   "source": [
    "Pass 6 words in, ask for 1 word out, try 1 time: answer is CORRECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f4e85f1c-6867-41b6-b261-c7f689e8db30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was\n",
      "Correct Next:   the\n",
      "Response:  the\n"
     ]
    }
   ],
   "source": [
    "predictor(6, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f8700-7c66-499e-bd98-5090f9b996f3",
   "metadata": {},
   "source": [
    "Pass 6 words in, ask for 4 words out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54cd2b9c-c1b8-496c-b17b-e47ef18f9ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was\n",
      "Correct Next:   the age of wisdom,\n",
      "Response:  the best of times\n"
     ]
    }
   ],
   "source": [
    "predictor(6, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ebc6178e-b3aa-41eb-ac09-68a8efe15ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the\n",
      "Correct Next:   age\n",
      "Response:  best\n"
     ]
    }
   ],
   "source": [
    "predictor(7, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "941099a5-d3b2-47a4-b222-d34205f56f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age\n",
      "Correct Next:   of\n",
      "Response:  of\n"
     ]
    }
   ],
   "source": [
    "predictor(8, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1cbc191d-e9cd-46f7-b736-cccf17a1c381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age\n",
      "Correct Next:   of wisdom, it was the age\n",
      "Response:  of wisdom.\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "predictor(8, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11e60f45-9220-426f-a682-adc1980bfaa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of\n",
      "Correct Next:   wisdom,\n",
      "Response:  wisdom\n"
     ]
    }
   ],
   "source": [
    "predictor(9, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8e4c32b1-195c-4b2e-be09-7f94279a0df3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of\n",
      "Correct Next:   wisdom, it was the age of\n",
      "Response:  wisdom.\n",
      "\n",
      "The best\n"
     ]
    }
   ],
   "source": [
    "predictor(9, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d5b4e7a-bb8d-4eac-bb75-5bd637c857c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of wisdom,\n",
      "Correct Next:   it\n",
      "Response:  it\n"
     ]
    }
   ],
   "source": [
    "predictor(10, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "895d6a37-cf8b-4c49-92cb-4f9505287508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of wisdom,\n",
      "Correct Next:   it was the age of foolishness,\n",
      "Response:  it was the age of foolishness\n"
     ]
    }
   ],
   "source": [
    "predictor(10, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4dfde8c-3e86-41d8-b44a-2c0a49e8a1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of wisdom,\n",
      "Correct Next:   it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness,\n",
      "Response:  it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it\n"
     ]
    }
   ],
   "source": [
    "predictor(10, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00824c-ad06-4d99-97f3-04d6e19bdafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1723087-34cb-4ff9-9512-e2f460926f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd3567-acfe-4877-8ab4-0bd138756fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff01e78-34c2-4cbf-ab9b-1ae85a925266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441528c-b049-452d-8fbb-349b8e5e193b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
