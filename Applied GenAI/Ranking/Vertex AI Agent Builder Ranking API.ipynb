{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66eae05",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FRanking&file=Vertex+AI+Agent+Builder+Ranking+API.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Ranking/Vertex%20AI%20Agent%20Builder%20Ranking%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FRanking%2FVertex%2520AI%2520Agent%2520Builder%2520Ranking%2520API.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Ranking/Vertex%20AI%20Agent%20Builder%20Ranking%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Ranking/Vertex%20AI%20Agent%20Builder%20Ranking%20API.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a917b-76ff-4bf9-acfa-a2dee73de0bc",
   "metadata": {},
   "source": [
    "# Vertex AI Agent Builder Ranking API\n",
    "\n",
    "- https://cloud.google.com/generative-ai-app-builder/docs/builder-apis\n",
    "- https://cloud.google.com/generative-ai-app-builder/docs/ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a314b240-7462-460e-a2fc-71473eeec863",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f819168-9044-4290-8359-1fc3ca28a150",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceabbf3b-92e5-46d3-8c41-73e2931e0899",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f8a81-8f01-4ff4-9e06-40753547850e",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2097a23d-c6ed-4b42-a547-a28fd95bc1be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.66.0'),\n",
    "    ('google.cloud.discoveryengine', 'google-cloud-discoveryengine')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23614cc3-e5d6-4593-8f9e-c80c995448c4",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5c3b12-8031-473e-833b-698524d57485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com\n",
    "!gcloud services enable discoveryengine.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e14c76-7168-4f91-9176-3607942d932c",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0258e31-b03f-4c19-8205-7ffdff9a11ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e35a211-ccd0-42be-8e38-dac55f9c8aca",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4332e-815b-4c4c-9618-7404cb8da03a",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a2f439-b760-47b7-9eac-02d0e22483eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f228e4-cbe7-416a-bfad-53d5dcda7f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'evaluation-check-grounding'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0abe3d-c518-4df3-8883-9fbd6c572e51",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69a24473-d3b6-4013-b453-71a355e4bc75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, shutil, json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import google.cloud.discoveryengine_v1 as discoveryengine\n",
    "from google.cloud import aiplatform\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "import vertexai.language_models # for text embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3edecf9-5faf-4788-9ed9-e9ce51fe34a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.66.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d97cc0f6-fb82-4836-80b7-1dd4ac1fbfdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discoveryengine.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5146c8-822e-4dcd-8175-f850b551f2af",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b54db18-916a-45fc-8639-a92c506b1535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vertex AI\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# Vertex AI Agent Builder APIs\n",
    "ranker = discoveryengine.RankServiceClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe8af0-8872-462c-a391-ab576f4b2a7a",
   "metadata": {},
   "source": [
    "---\n",
    "## Text & Embeddings For Examples\n",
    "\n",
    "This repository contains a [section for document processing (chunking)](../Chunking/readme.md) that includes an [example of processing a PDF with the Document AI Layout Parser](../Chunking/Process%20Documents%20-%20Document%20AI%20Layout%20Parser.ipynb).  The chunks of text from that workflow are stored with this repository and loaded by another companion workflow that augments the chunks with text embeddings: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb).\n",
    "\n",
    "The following code will load the version of the chunks that includes text embeddings and prepare it for a local example of retrival augmented generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a072314-168f-4818-a3f5-45b3a7fe1cec",
   "metadata": {},
   "source": [
    "### Get The Documents\n",
    "\n",
    "If you are working from a clone of this notebooks [repository](https://github.com/statmike/vertex-ai-mlops) then the documents are already present. The following cell checks for the documents folder and if it is missing gets it (`git clone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b529be8-6310-4ab4-851e-12188c36b50e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = '../Embeddings/files/embeddings-api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ab53d8b-be73-45e2-94d1-0d460c131242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Found in folder `../Embeddings/files/embeddings-api`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_dir):\n",
    "    print('Retrieving documents...')\n",
    "    parent_dir = os.path.dirname(local_dir)\n",
    "    temp_dir = os.path.join(parent_dir, 'temp')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops {temp_dir}/vertex-ai-mlops\n",
    "    shutil.copytree(f'{temp_dir}/vertex-ai-mlops/Applied GenAI/Embeddings/files/embeddings-api', local_dir)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'Documents are now in folder `{local_dir}`')\n",
    "else:\n",
    "    print(f'Documents Found in folder `{local_dir}`')             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486cada-f594-4658-a0c6-428a4b51ad6e",
   "metadata": {},
   "source": [
    "### Load The Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4d629f3-a05e-4352-912f-429fad7d6701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(local_dir+'/chunk-embeddings.jsonl', 'r') as f:\n",
    "    chunks = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a4569-a25f-4999-b057-a81d0ebbd6be",
   "metadata": {},
   "source": [
    "### Review A Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf3adfea-c4df-4f09-923c-563549f5809e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'predictions', 'status'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7f47191-4284-40ec-b162-c7f418f082a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c2'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['instance']['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3cd8b4da-ad26-4aa9-9bb1-24163443f48f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# OFFICIAL BASEBALL RULES\n",
      "\n",
      "## Official Baseball Rules 2023 Edition\n",
      "\n",
      "### JOINT COMPETITION COMMITTEE\n",
      "\n",
      "|-|-|-|\n",
      "| Bill DeWitt | Whit Merrifield | Austin Slater |\n",
      "| Jack Flaherty | Bill Miller | John Stanton, Chair |\n",
      "| Tyler Glasnow | Dick Monfort | Tom Werner |\n",
      "| Greg Johnson | Mark Shapiro |  |\n",
      "\n",
      "Committee Secretary Paul V. Mifsud, Jr. Copyright © 2023 by the Office of the Commissioner of Baseball\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0]['instance']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b36d9449-020f-47e5-a4d7-741e5e95a22b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.008681542240083218,\n",
       " 0.06999468058347702,\n",
       " 0.003673204220831394,\n",
       " 0.019888797774910927,\n",
       " 0.016285404562950134,\n",
       " 0.035664502531290054,\n",
       " 0.06200747936964035,\n",
       " 0.05597030743956566,\n",
       " 0.0034793149679899216,\n",
       " -0.024485772475600243]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['predictions'][0]['embeddings']['values'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee9ae5-2d7f-43d4-8b37-d22eabd24981",
   "metadata": {},
   "source": [
    "---\n",
    "## Simple Retrieval Augmented Generation (RAG)\n",
    "\n",
    "Embeddings can be used with math to measure similarity.  For deeper details into this checkout the companion workflow here: [The Math of Similarity](./The%20Math%20of%20Similarity.ipynb).  Retrieval systems handle the storage and math of similarity as a service.  For an overview of Google Cloud based solutions for retrieval check out [this companion series](../Retrieval/readme.md).\n",
    "\n",
    "The content below motivates retrieval with the embeddings that accompany the text chunks using a local vector database with brute force matching using Numpy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22914402-06bc-4de0-949d-f0a5b7c58266",
   "metadata": {},
   "source": [
    "### Vector DB With Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac71eb01-6561-470d-a6a7-0ff7228ba4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_db = [\n",
    "    [\n",
    "        chunk['instance']['chunk_id'],\n",
    "        chunk['instance']['content'],\n",
    "        chunk['predictions'][0]['embeddings']['values'],\n",
    "    ]\n",
    "    for chunk in chunks\n",
    "]\n",
    "vector_index = np.array([row[2] for row in vector_db])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19297567-91fc-4eda-97c0-3a0f2249264b",
   "metadata": {},
   "source": [
    "### Models: Embeddings, Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e5cab-45f2-4211-9d59-31e5aa67b32b",
   "metadata": {},
   "source": [
    "Connect to models for text embeddings and text generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a7c1580-758c-43d5-8aaf-fefb7b2be60f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')\n",
    "llm = vertexai.generative_models.GenerativeModel(\"gemini-1.5-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3a42d-a141-48a9-9351-45e6152cd35e",
   "metadata": {},
   "source": [
    "Define a question that is the start of our prompt to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c699c353-fbd4-4a6d-8b52-2b54dfd820c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"What are the dimensions of a base?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba8d0d-c59e-4e08-987f-8ae69782ce97",
   "metadata": {},
   "source": [
    "Get an ungrounded response to the question with the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c939531c-ef81-4fea-851f-e4776d3ebe4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide me with more context!  \"Base\" can refer to many different things, each with its own dimensions. \n",
      "\n",
      "For example, are you talking about:\n",
      "\n",
      "* **The base of a geometric shape?**  \n",
      "    * In this case, the dimensions would be the length and width of the base.  \n",
      "    * For example, a rectangle might have a base of 10cm and a height of 5cm.\n",
      "* **The base of a number system?**\n",
      "    * The base of a number system is the number of unique digits it uses. For example, the base of the decimal system is 10 (0-9).\n",
      "* **The base of a container?**\n",
      "    * The dimensions would be the length, width, and height of the base.\n",
      "* **The base of a word?**\n",
      "    * The base of a word is its root meaning, without any prefixes or suffixes.\n",
      "* **A military base?** \n",
      "    * The dimensions would be the area of the base and its geographical location. \n",
      "\n",
      "Please clarify what you mean by \"base\" so I can give you the specific dimensions you need. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.generate_content(question).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cab7ac-0397-4c89-b477-0547d50a3f8d",
   "metadata": {},
   "source": [
    "Get an embedding for the question to use in retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98c6e564-1e43-49f4-b601-0946a0670bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.026682045310735703,\n",
       " 0.011593513190746307,\n",
       " 0.028523651883006096,\n",
       " -0.0017065361607819796,\n",
       " 0.01946176588535309,\n",
       " 0.0031198114156723022,\n",
       " 0.07915323227643967,\n",
       " -0.005078596994280815,\n",
       " -0.006295712199062109,\n",
       " 0.04943541809916496]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = embedder.get_embeddings([question])[0].values\n",
    "question_embedding[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f90e5f-be46-441e-9bf4-73843de8feb9",
   "metadata": {},
   "source": [
    "### Retrieval: Matching With Numpy\n",
    "\n",
    "Use dot product to calculate similarity and find matches for a query embedding.  Why dot product?  Check out the companion workflow: [The Math of Similarity](./The%20Math%20of%20Similarity.ipynb)\n",
    "\n",
    "> **NOTE:**  This will calculate the similarity for all embeddings vectors stored in the local vector db which is just a Numpy array here.  This is very fast because there are <200 embeddings vectors.  As this scales it would be better to consider a solution that searches a subset of embeddings.  More details on retrieval solutions can be found in [Retrieval](../Retrieval/readme.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e255a7ad-24eb-409d-a8f3-affa42b9b490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38, 0.5843799337008113),\n",
       " (36, 0.5724333016720691),\n",
       " (836, 0.5244194362041271),\n",
       " (40, 0.5126844935129918),\n",
       " (26, 0.5033481946111171)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = np.dot(question_embedding, vector_index.T)\n",
    "matches = np.argsort(similarity)[::-1][:5].tolist()\n",
    "matches = [(match, similarity[match]) for match in matches]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a013601-b36b-4c3e-ade1-8e1cd6f87a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1 (0.58) is chunk: c38:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.02 Home Base\n",
      "\n",
      "Home base shall be marked by a five-sided slab of whitened rubber. It shall be a 17-inch square with two of the corners removed so that one edge is 17 inches long, two adjacent sides are 8\\frac{1}{2} inches and the remaining two sides are 12 inches and set at an angle to make a point.\n",
      "###################################################\n",
      "Match 2 (0.57) is chunk: c39:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.02 Home Base\n",
      "\n",
      "It shall be set in the ground with the point at the intersection of the lines extending from home base to first base and to third base; with the 17-inch edge facing the pitcher's plate, and the two 12-inch edges coinciding with the first and third base lines. The top edges of home base shall be beveled and the base shall be fixed in the ground level with the ground surface. (See drawing D in Appendix 2.) 3\n",
      "###################################################\n",
      "Match 3 (0.52) is chunk: c838:\n",
      "# APPENDICES\n",
      "\n",
      "## Appendix 2\n",
      "\n",
      "Diagram No. 2 Layout at Home Plate, 1st, 2nd, and 3rd Bases 18\" A 18\" 90° LAYOUT AT SECOND BASE FOR LAYOUT AT PITCHER'S PLATE SEE DIAGRAM NO. 3 90° 6\" 17\" 6\" D E 3'0\" 3'0\" 4'0\" 4 C 43\" LAYOUT AT HOME BASE DIAGRAM NO. 2 LEGEND A 1st, 2nd, 3rd BASES BATTER'S BOX B B C CATCHER'S BOX D HOME BASE E PITCHER'S PLATE Rev2023RW 161 90° 4 FOUL LINE LAYOUT AT FIRST BASE\n",
      "###################################################\n",
      "Match 4 (0.51) is chunk: c40:\n",
      "# Rule 2.03 to 2.05\n",
      "\n",
      "## 2.03 The Bases\n",
      "\n",
      "First, second and third bases shall be marked by white canvas or rubber-covered bags, securely attached to the ground as indicated in Diagram 2. The first and third base bags shall be entirely within the infield. The second base bag shall be centered on second base. The bags shall be 18 inches square, not less than three nor more than five inches thick, and filled with soft material.\n",
      "###################################################\n",
      "Match 5 (0.50) is chunk: c31:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.01 Layout of the Field\n",
      "\n",
      "When location of home base is determined, with a steel tape measure 127 feet, 3\\frac{3}{8} inches in desired direction to establish second base. From home base, measure 90 feet toward first base; from second base, measure 90 feet toward first base; the intersection of these lines establishes first base. From home base, measure 90 feet toward third base; from second base, measure 90 feet toward third base; the intersection of these lines establishes third base.\n",
      "###################################################\n"
     ]
    }
   ],
   "source": [
    "for m, match in enumerate(matches):\n",
    "    print(f\"Match {m+1} ({match[1]:.2f}) is chunk: {vector_db[match[0]][0]}:\\n{vector_db[match[0]][1]}\\n###################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae7867-438f-45f2-9b42-12179acfeb15",
   "metadata": {},
   "source": [
    "### Generation: Q&A With Gemini Grounded With RAG\n",
    "\n",
    "Provide the matched chunks of text along with the question as a prompt to a generative model for a grounded answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e006bf-3ee4-4c50-ae61-a807897967b1",
   "metadata": {},
   "source": [
    "#### Prompt Building Function\n",
    "\n",
    "Use the matching chunks as context for the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d14d98a-e6ce-419d-b522-81be3b144e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prompt(question, top_n = 5):\n",
    "    # get embedding for question\n",
    "    question_embedding = embedder.get_embeddings([question])[0].values\n",
    "    # get top_n matches:\n",
    "    similarity = np.dot(question_embedding, vector_index.T)\n",
    "    matches = np.argsort(similarity)[::-1][:top_n].tolist()\n",
    "    matches = [(match, similarity[match]) for match in matches]\n",
    "    # construct prompt:\n",
    "    prompt = ''\n",
    "    for m, match in enumerate(matches):\n",
    "        prompt += f\"Context {m+1}:\\n{vector_db[match[0]][1]}\\n\\n\"\n",
    "    prompt += f'Answer the following question using the provided contexts:\\n{question}'\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8c82dd73-70fd-4a1c-b154-737ae75f2b41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.02 Home Base\n",
      "\n",
      "Home base shall be marked by a five-sided slab of whitened rubber. It shall be a 17-inch square with two of the corners removed so that one edge is 17 inches long, two adjacent sides are 8\\frac{1}{2} inches and the remaining two sides are 12 inches and set at an angle to make a point.\n",
      "\n",
      "Context 2:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.02 Home Base\n",
      "\n",
      "It shall be set in the ground with the point at the intersection of the lines extending from home base to first base and to third base; with the 17-inch edge facing the pitcher's plate, and the two 12-inch edges coinciding with the first and third base lines. The top edges of home base shall be beveled and the base shall be fixed in the ground level with the ground surface. (See drawing D in Appendix 2.) 3\n",
      "\n",
      "Context 3:\n",
      "# APPENDICES\n",
      "\n",
      "## Appendix 2\n",
      "\n",
      "Diagram No. 2 Layout at Home Plate, 1st, 2nd, and 3rd Bases 18\" A 18\" 90° LAYOUT AT SECOND BASE FOR LAYOUT AT PITCHER'S PLATE SEE DIAGRAM NO. 3 90° 6\" 17\" 6\" D E 3'0\" 3'0\" 4'0\" 4 C 43\" LAYOUT AT HOME BASE DIAGRAM NO. 2 LEGEND A 1st, 2nd, 3rd BASES BATTER'S BOX B B C CATCHER'S BOX D HOME BASE E PITCHER'S PLATE Rev2023RW 161 90° 4 FOUL LINE LAYOUT AT FIRST BASE\n",
      "\n",
      "Context 4:\n",
      "# Rule 2.03 to 2.05\n",
      "\n",
      "## 2.03 The Bases\n",
      "\n",
      "First, second and third bases shall be marked by white canvas or rubber-covered bags, securely attached to the ground as indicated in Diagram 2. The first and third base bags shall be entirely within the infield. The second base bag shall be centered on second base. The bags shall be 18 inches square, not less than three nor more than five inches thick, and filled with soft material.\n",
      "\n",
      "Context 5:\n",
      "# 2.00-THE PLAYING FIELD\n",
      "\n",
      "## 2.01 Layout of the Field\n",
      "\n",
      "When location of home base is determined, with a steel tape measure 127 feet, 3\\frac{3}{8} inches in desired direction to establish second base. From home base, measure 90 feet toward first base; from second base, measure 90 feet toward first base; the intersection of these lines establishes first base. From home base, measure 90 feet toward third base; from second base, measure 90 feet toward third base; the intersection of these lines establishes third base.\n",
      "\n",
      "Answer the following question using the provided contexts:\n",
      "What are the dimensions of a base?\n"
     ]
    }
   ],
   "source": [
    "print(get_prompt(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3434480-243a-4fe7-87fc-86de216f86bf",
   "metadata": {},
   "source": [
    "### Grounded Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85bb2810-eb8e-4581-82ee-54d2f387689b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer depends on which type of base you are asking about:\n",
      "\n",
      "* **Home Base:** It is a five-sided slab of whitened rubber, with dimensions:\n",
      "    * One edge: 17 inches long\n",
      "    * Two adjacent sides: 8 1/2 inches each\n",
      "    * Remaining two sides: 12 inches each, set at an angle to make a point.\n",
      "* **First, Second, and Third Bases:** These are white canvas or rubber-covered bags, with dimensions:\n",
      "    * 18 inches square\n",
      "    * 3 to 5 inches thick\n",
      "\n",
      "Therefore, the dimensions of a base depend on whether it is the home base or the other bases. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.generate_content(get_prompt(question)).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb02e4e-b1d0-44de-9060-56efd2ebb167",
   "metadata": {},
   "source": [
    "---\n",
    "## Ranking API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7736f-cf67-4451-8165-db65b4f6cf37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e85c2-bd32-4feb-9ba2-819745bb5e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e2596-9f35-4515-a951-e54e911bf107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbbb74-6323-4ca0-915d-2b57a3363be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f204c1-78ce-4283-9d64-cb71ff5f819c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
