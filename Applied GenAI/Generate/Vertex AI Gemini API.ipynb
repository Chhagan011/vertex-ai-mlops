{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f803d3",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FGenerate&file=Vertex+AI+Gemini+API.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Generate/Vertex%20AI%20Gemini%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FGenerate%2FVertex%2520AI%2520Gemini%2520API.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Generate/Vertex%20AI%20Gemini%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Generate/Vertex%20AI%20Gemini%20API.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a02ee-78e4-4618-8c0e-6103af31af0b",
   "metadata": {},
   "source": [
    "# Vertex AI Gemini API\n",
    "\n",
    "Gemini is a family of foundation models that you can test, deploy, and customize using Vertex AI.  These models are hosted as an API that you can easily test: [with code](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal), or interactively [with Vertex AI Studio](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart).\n",
    "\n",
    "[Gemini models](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models) are part of the family of [Google models](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models) you will find in the [Vertex AI Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models).  This also includes [Partner Models](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-partner-models), like Anthropic Claude and Llama, as well as [Open models](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/use-open-models) like Gemma and Hex-LLM.\n",
    "\n",
    "The focus of this workflow is a deep dive into all of the many features of the [Gemini API](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference).\n",
    "\n",
    "**References:**\n",
    "\n",
    "\n",
    "---\n",
    "**depricate this content once complete**\n",
    "\n",
    "This notebook will hold an expanded overview of the Gemini API that is current found at the top of this workflow:\n",
    "\n",
    "Combining content from:\n",
    "- [Getting Started - Vertex AI GenAI Python Client](../Getting%20Started%20-%20Vertex%20AI%20GenAI%20Python%20Client.ipynb)\n",
    "- [Python Asynchronous API Calls](../Python%20Asynchronous%20API%20Calls.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d775874-a326-4f3b-9ca6-951beede7f8e",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6236e81b-1ec3-4ff1-8aba-1e1a31c0b133",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a83446b2-264c-42e7-a6c7-2a2bfd5bd564",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8473b88-a178-4ea5-915d-6513d4cd98c2",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f15cef-33c6-4128-9a2c-e147670105e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.69.0'),\n",
    "    ('numpy', 'numpy'),\n",
    "    ('matplotlib', 'matplotlib')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea96b6-a1c0-4dfc-afa2-edd787b2beba",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df5af09-f935-42c5-b164-c4a04e482752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b17c54-6fc4-4131-b554-ad5147d476af",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26fae04c-1552-4ef7-a31e-e5239acaf3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43852628-3942-4c89-99da-cf615cb68237",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64816130-dbc2-46a8-b0af-effe8dbad749",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14da303d-da20-4dcb-bd71-9d6a4a3a7a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc7684e-b04b-4aed-8333-788b14756708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'gemini-api'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d518b-890d-48c9-9399-ba997c893687",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa106475-6551-4574-82c9-1c32b0971661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io, base64\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "import vertexai.generative_models # for Gemini Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc6458a-218b-41d7-adf3-14226ccacf5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.69.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5b8fe-857c-4cc4-ae45-d969abbb5f04",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3945a2fa-f350-4b7f-9432-7acd020e7067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8850a-f1d9-4359-beb1-0da23ffbd94b",
   "metadata": {},
   "source": [
    "---\n",
    "## Gemini Models\n",
    "\n",
    "Select one of the [supported Gemini models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models) and read more about the characteristics of each [here](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d28c7-d913-4649-a150-2e985b445b80",
   "metadata": {},
   "source": [
    "### Setup Model\n",
    "\n",
    "Here the [Gemini 1.5 Flash model with version 002](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash) is selected. It has these characteristics (to name a few):\n",
    "- Max Input Tokens: 1,048,576\n",
    "- Max Output Tokens: 8,192\n",
    "- Max image:\n",
    "    - raw size 20MB\n",
    "    - base64 encoded size 7MB\n",
    "    - number per prompt 3000\n",
    "- Max video:\n",
    "    - length 1 hour\n",
    "    - number per prompt 10\n",
    "- Max audio:\n",
    "    - length 8.4 hours\n",
    "    - number per prompt 1\n",
    "- Max PDF:\n",
    "    - size 30 MB\n",
    "- 102 [Languages](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#languages-gemini) for understanding and responding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b41bcd4-1692-46d5-aeb6-8b7acf2359a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemini = vertexai.generative_models.GenerativeModel(\"gemini-1.5-flash-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2ec99-7cdb-4d52-8ce6-296ddd094b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91acaeb3-65c6-4f7b-8c5e-81ef471b5bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc1634a-901a-4c6b-8e0d-eca4f4f47d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003adf6-ef1b-40c5-a833-006bee01b453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03725e6-1b7b-43b1-b138-3e4466060ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43a8e5-d0ff-47dd-a0f6-cbbd2f951098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7bd55-e241-4e5f-b373-8c29c5e2db91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc227c6f-bb6c-4082-a010-61df2e385daa",
   "metadata": {},
   "source": [
    "Todo:\n",
    "- call\n",
    "- generation config call: break down by parameter\n",
    "- system instruction\n",
    "- multiple calls - async\n",
    "- multimodal: image, video, audio, pdf\n",
    "- chat\n",
    "- section on limits, provision and dynamic (002 and higher)\n",
    "- handling errors in responses\n",
    "- caching\n",
    "- safety config\n",
    "- batch\n",
    "- labels\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89d9d7-bb40-4e26-95a9-ecd13306c623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
