{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f4886d",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2Farchitectures&file=move_notebooks.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/architectures/move_notebooks.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2Farchitectures%2Fmove_notebooks.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/architectures/move_notebooks.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/architectures/move_notebooks.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f2d1c2-da30-4756-93cf-47ac14bce0db",
   "metadata": {},
   "source": [
    "# Moving Notebook Files\n",
    "\n",
    "Used to move files or folders to different folders within the repo\n",
    "- preserves files commmit history by using `git mv`\n",
    "- Will fix relative links within markdown cells of notebooks and within markdown files.\n",
    "- adds banner at top of file to indicate the files move and status\n",
    "\n",
    "Details:\n",
    "- Move the file/folder with `git mv`\n",
    "    - commit the staged move\n",
    "- Create a list of moved files that are either `.md` or `.ipynb` files\n",
    "- Find and fix and relative links inside these files\n",
    "- Detect which files had changes and stage+commit them\n",
    "\n",
    "IN PROGRESS:\n",
    "- Add/Edit a banner for the file that has notes on the files location change: date, old location, new/current location\n",
    "    - stage+commit these changes\n",
    "- Check all other files in the repository for links to the old file location and update to the new file location\n",
    "    - stage+commit these changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f76654f-35f2-43ad-a162-132b8a1698e5",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10b8a8-2e5b-4b6b-8ad0-af72590506fe",
   "metadata": {},
   "source": [
    "Installs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a5dd3fe-6e2e-4edd-a64d-92b9ce0f8466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install GitPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f51afa-a5d7-4100-ad3b-68d9610b2447",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05f17c9c-bd1d-46d8-83cf-8453c0cc1a65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nbformat.NO_CONVERT"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, urllib.parse, IPython, pathlib, nbformat, re, git, datetime\n",
    "\n",
    "nbformat.NO_CONVERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f861a9f-b679-4ccf-a301-602780ab76f2",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bc93a0-f0c0-47b7-98a8-3be92a5d64a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/vertex-ai-mlops/Applied GenAI/resources'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d458b2f-9af4-4fee-af5b-27709ce91720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/jupyter/vertex-ai-mlops'),\n",
       " PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/Vertex AI Search'),\n",
       " PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search'))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `from_path` and `to_path` can be a folder or a specific file.\n",
    "\n",
    "repo_path = pathlib.Path('/home/jupyter/vertex-ai-mlops')\n",
    "from_path = repo_path.joinpath('Applied GenAI/Vertex AI Search')\n",
    "to_path = repo_path.joinpath('Applied GenAI/legacy/Vertex AI Search')\n",
    "repo_path, from_path, to_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04f689-f552-4657-8e03-be5bf3cff149",
   "metadata": {},
   "source": [
    "Clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "058dae52-4435-4612-aa80-56800f24f978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo = git.Repo(repo_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83665803-247a-463a-98fa-e8995c97ae0c",
   "metadata": {},
   "source": [
    "files = [\n",
    "    \"Summarize Conversations - Text and Audio.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - USGA Rules For Golf.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A v2 - MLB Rules For Baseball.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - NHL Rules For Hockey.ipynb\",\n",
    "    \"Vertex AI GenAI For BigQuery Metadata - Make Better Tables.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - Healthcare Benefits Member Handbook.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - MCC Laws For Cricket.ipynb\",\n",
    "    \"Vertex AI Matching Engine For Document Q&A.ipynb\",\n",
    "    \"Vertex AI GenAI For Rewriting - BigQuery Advisor With Codey.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - Annual Report.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A v2 - Deed Of Trust.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - FAA Regulations.ipynb\",\n",
    "    \"Vertex AI GenAI For BigQuery Q&A - Overview.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - Local Government Trends.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A v2 - Employee Handbook.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - MLB Rules For Baseball.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - NFL Rules For Football.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - NBA Rules For Basketball.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - IFAB Laws For Soccer.ipynb\",\n",
    "    \"Vertex AI GenAI For Document Q&A - Municipal Securities.ipynb\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec3bf5-3fa6-44d7-9a64-7f7f3a6b926c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Prepare For File Changes\n",
    "\n",
    "As the code in this workflow makes changes it will also stage and commit the changes.  For this reason it is important that no files be currently staged.  Take a moment to review staged files and finish committing them or remove them from staging.  This section will print staged files.  There is also code that will unstage any staged files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbd35e98-2873-4ece-9615-e79154e4582a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files are staged for commit.\n"
     ]
    }
   ],
   "source": [
    "staged_files = [item.a_path for item in repo.index.diff(\"HEAD\")]\n",
    "\n",
    "if staged_files:\n",
    "    print(\"Staged files:\")\n",
    "    for file in staged_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"No files are staged for commit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea210c-0e1c-4f6b-8db1-ddf3759c3811",
   "metadata": {},
   "source": [
    "**UNSTAGE ALL FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0396edf2-c066-4105-a05a-016ed8fb134f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files to unstage.\n"
     ]
    }
   ],
   "source": [
    "if staged_files:\n",
    "    print('Unstaging files listed above:')\n",
    "    repo.git.restore('--staged', '.')\n",
    "else:\n",
    "    print('No files to unstage.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908460ab-7d36-4191-bfeb-3d7bfd6305ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Move Folder/File\n",
    "\n",
    "This is a git repository so it is important to move the files with the commit history preserved using `git mv old_file new_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "66b44546-c915-425f-8074-24387e37fb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo = git.Repo(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "987a02bb-1adb-44be-bd92-d39211b1f248",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9aa40a35-9a47-4f6e-a7aa-473b1e398140",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ca537a9e-e001-477f-aa51-5d6aff0128cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears the file(s) have already moved to:\n",
      "\t/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search\n"
     ]
    }
   ],
   "source": [
    "if from_path.exists():\n",
    "    repo.git.mv(from_path, to_path)\n",
    "    print(f'Files moved from: \\n\\t{from_path}\\nto:\\n\\t{to_path}')\n",
    "    repo.index.commit('Moved file')\n",
    "    print(f'Moved files commited.')\n",
    "elif to_path.exists():\n",
    "    print(f'It appears the file(s) have already moved to:\\n\\t{to_path}')\n",
    "else:\n",
    "    print('Make sure the file(s) exists.  Currently not found in the from or to location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddcdcd3-9106-4faf-b563-e8f885db29f0",
   "metadata": {},
   "source": [
    "---\n",
    "## Files List\n",
    "\n",
    "Create a list of files (.md and .ipynb) including their new full path. If `to_path` was a file then the files list will have just the one file in it.  If `to_path` was a folder then all files in the folder will be included in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a0d98b49-244f-4cb2-abee-26610834ec12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def file_list(from_path, to_path):\n",
    "    # returns a list of tuples for files that contain (from_file_path, to_file_path)\n",
    "    files = []\n",
    "    if to_path.is_dir():\n",
    "        for nb in to_path.glob(\"*.ipynb\"):\n",
    "            files.append(\n",
    "                (\n",
    "                    from_path.joinpath(nb.name),\n",
    "                    nb\n",
    "                )\n",
    "            )\n",
    "        for md in to_path.glob(\"*.md\"):\n",
    "            files.append(\n",
    "                (\n",
    "                    from_path.joinpath(md.name),\n",
    "                    md\n",
    "                )\n",
    "            )\n",
    "    elif to_path.is_file() and to_path.suffix in ['.md', '.ipynb']:\n",
    "        files.append(\n",
    "            (\n",
    "                from_path.joinpath(to_path.name),\n",
    "                to_path\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(f'Check for existance of file/folder: {to_path}')\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0cbeb89b-a80c-4351-b5d2-57d993eba875",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/Vertex AI Search/Vertex AI Search Python Client Overview.ipynb'),\n",
       "  PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search/Vertex AI Search Python Client Overview.ipynb')),\n",
       " (PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/Vertex AI Search/vertex_search_setup.md'),\n",
       "  PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search/vertex_search_setup.md')),\n",
       " (PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/Vertex AI Search/readme.md'),\n",
       "  PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search/readme.md'))]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = file_list(from_path, to_path)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af29f511-03f7-4903-940b-4a619d7381bc",
   "metadata": {},
   "source": [
    "---\n",
    "## Find and Fix Links\n",
    "\n",
    "Go through the contents of each `.ipynb` and `.md` file and detect any relative links used in markdown or HTML:\n",
    "- resolve the link to an absolute path using the `from_path`\n",
    "- check to see if the link exists\n",
    "- prepare a new version that is relative given the `to_path`\n",
    "- check to see if the new link exists\n",
    "- update the relative link in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "874d7419-1c4b-479a-a520-b8598a616eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def link_fixer(from_file_path, to_file_path, link, files):\n",
    "    # return new_link, a version of link (from_file_path) that is update to work with the new file at to_file_path\n",
    "    decoded_link = urllib.parse.unquote(link)\n",
    "    abs_link_path_from = (from_file_path.parent / decoded_link).resolve()\n",
    "    also_moved = any(ffp[0] == abs_link_path_from for ffp in files)\n",
    "    try:\n",
    "        # if the linked file exists or was also moved then continue\n",
    "        assert abs_link_path_from.exists() or also_moved, f\"This link is broken before the move:\\n\\t{abs_link_path_from}\"\n",
    "        if also_moved:\n",
    "            new_link = decoded_link\n",
    "        else:\n",
    "            common_path_to = pathlib.Path(os.path.commonpath([to_file_path, abs_link_path_from]))\n",
    "            new_link = (len(to_file_path.parent.parts) - len(common_path_to.parts))*'../' + str(abs_link_path_from.relative_to(common_path_to))\n",
    "        abs_link_path_to = (to_file_path.parent / new_link).resolve()\n",
    "\n",
    "        try:\n",
    "            assert abs_link_path_from == abs_link_path_to or abs_link_path_to.exists(), f\"This function failed to fix the link:\\n\\t{abs_link_path_from}\"\n",
    "            new_link = urllib.parse.quote(new_link)\n",
    "            return new_link\n",
    "        except AssertionError as e:\n",
    "            print(f\"Error fixing link: {e}\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"Error fixing link: {e}\")\n",
    "        \n",
    "def find_relative_links(from_file_path, to_file_path, files):\n",
    "    # returns a list of tuples for files that contain (from_file_path, to_file_path)\n",
    "    relative_links = []\n",
    "    regex = r\"(?:\\[.*?\\]\\((.*?)\\)|<\\w+\\s+[^>]*?(?:href|src)=(['\\\"])(.*?)\\2)\" # capture markdown and qouted links in href and src\n",
    "    if to_file_path.suffix == '.ipynb':\n",
    "        nb = nbformat.read(to_file_path, nbformat.NO_CONVERT)\n",
    "        for cell in nb.cells:\n",
    "            if cell.cell_type == 'markdown':\n",
    "                links = re.findall(regex, cell.source)\n",
    "                for link in links:\n",
    "                    link = link[0] or link[2]\n",
    "                    if not link.startswith(\"http\") and not link.startswith('/'):\n",
    "                        new_link = link_fixer(from_file_path, to_file_path, link, files)\n",
    "                        relative_links.append((from_file_path, to_file_path, link, new_link))\n",
    "                        if new_link and new_link != link:  # Check if the link actually changed \n",
    "                            cell.source = cell.source.replace(link, new_link)\n",
    "        # Save the modified notebook\n",
    "        nbformat.write(nb, to_file_path)\n",
    "    elif to_file_path.suffix == '.md':\n",
    "        with open(to_file_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "            links = re.findall(regex, content)\n",
    "            for link in links:\n",
    "                link = link[0] or link[2]\n",
    "                if not link.startswith('http') and not link.startswith('/'):\n",
    "                    new_link = link_fixer(from_file_path, to_file_path, link, files)\n",
    "                    relative_links.append((from_file_path, to_file_path, link, new_link))\n",
    "                    if new_link and new_link != link:\n",
    "                        content = content.replace(link, new_link)\n",
    "            # Save the modified markdown file\n",
    "            with open(to_file_path, \"w\") as f:\n",
    "                f.write(content)\n",
    "                    \n",
    "    return relative_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "abba860a-019f-43c1-b4a2-0be3ffff7833",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Links already reviewed and fixed: 14\n"
     ]
    }
   ],
   "source": [
    "if 'relative_links' in locals() or 'relative_links' in globals():\n",
    "    print(f'Relative Links already reviewed and fixed: {len(relative_links)}')\n",
    "else:\n",
    "    relative_links = []\n",
    "    for file in files:\n",
    "        relative_links.extend(\n",
    "            find_relative_links(*file, files)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c37fea7c-ee52-403c-a09e-a0b00eafeed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#relative_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38594d-7cf5-4fab-ad94-56ef2c260323",
   "metadata": {},
   "source": [
    "---\n",
    "## Changed Files\n",
    "Detect which files had changes and stage+commit them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "afc003dc-fdf4-405b-906a-a062a449ad54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_files = list(set([file[1] for file in relative_links if file[3] and file[3] != file[2]]))\n",
    "changed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3db1e08d-1441-4c19-8e56-de750b9f0a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for changed_file in changed_files:\n",
    "    # check for unstaged changes in the file\n",
    "    diff_list = repo.index.diff(None, paths=[str(changed_file)])\n",
    "    # if unstaged changes, stage them\n",
    "    if diff_list:\n",
    "        repo.git.add(str(changed_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4597f870-e903-4c2b-b3d0-f9ce151c12c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if staged changes then commit them\n",
    "if repo.index.diff(\"HEAD\"):\n",
    "    repo.index.commit(\"Fixed relative links after moving this file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e83e2b-c56f-40db-a23a-779754ccc05b",
   "metadata": {},
   "source": [
    "---\n",
    "## Add/Edit Banner With Location Change History\n",
    "Make a section at the top of .md and .ipynb files indicating location changes with dates.  Files with changes will be staged+commit.\n",
    "\n",
    "---\n",
    "Not production code but this is a working version.  These are test that I do to make sure it is working properly:\n",
    "- run and check each file for markdown code and preview the display\n",
    "- rerun without changes to verify that it does not further update the files\n",
    "- rerun with the `change_note` changed to the version with tomorrows date, ensure that it adds change note to the files\n",
    "- rerun with the same tomorrow date for `change_note` and verify it does not further update the files\n",
    "- discard all changes\n",
    "- ensure `change_note` is set to today's date version.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "73169355-2df6-4a0c-92d8-5bb59c6201ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update = 0\n",
    "for from_file_path, to_file_path in files:\n",
    "    # change note construction\n",
    "    change_lead = f\"---\\n\\n**File Move Notices**\\n\\nThis file moved locations:\"\n",
    "    change_note = f\"\"\"\\n- On {datetime.date.today().strftime(\"%m/%d/%Y\")} (mm/dd/yyyy)\\n\\t- From: `{from_file_path.relative_to(repo_path)}`\\n\\t- To: `{to_file_path.relative_to(repo_path)}`\"\"\"\n",
    "    #change_note = f\"\"\"\\n- On {(datetime.date.today()+datetime.timedelta(days=1)).strftime(\"%m/%d/%Y\")} (mm/dd/yyyy)\\n\\t- From: `{from_file_path.relative_to(repo_path)}`\\n\\t- To: `{to_file_path.relative_to(repo_path)}`\"\"\"\n",
    "    change_wrap = f\"\\n---\\n<!---end of move notices--->\\n\\n\"\n",
    "    \n",
    "    # notebook files\n",
    "    if to_file_path.suffix == \".ipynb\":\n",
    "        nb = nbformat.read(to_file_path, nbformat.NO_CONVERT)\n",
    "    \n",
    "        # detect existing header in file\n",
    "        if nb['cells'][0]['cell_type'] == 'markdown':\n",
    "            content = nb['cells'][0]['source']\n",
    "            if content.startswith('<!--- header table --->') or content.startswith('![tracker](https://'):\n",
    "                start_cell = 1 # second cell\n",
    "            else:\n",
    "                start_cell = 0 # first cell\n",
    "        \n",
    "        # detect existing file change info - after header\n",
    "        if nb['cells'][start_cell]['cell_type'] == 'markdown':\n",
    "            content = nb['cells'][start_cell]['source']\n",
    "            if content.startswith(change_lead):\n",
    "                changes = content[0:(content.index(change_wrap)+len(change_wrap))]\n",
    "                content = content[(content.index(change_wrap)+len(change_wrap)):]\n",
    "            else:\n",
    "                changes = ''\n",
    "        else:\n",
    "            print('No starting markdown cell')\n",
    "            \n",
    "        # edit/update change info\n",
    "        if change_lead not in changes and len(changes) < 1:\n",
    "            changes = change_lead+change_note+change_wrap\n",
    "            content = changes+content\n",
    "            update += 1\n",
    "            nb['cells'][start_cell]['source'] = content\n",
    "            nbformat.write(nb, to_file_path)\n",
    "            # stage file here\n",
    "            repo.git.add(str(to_file_path))\n",
    "        elif change_note not in changes:\n",
    "            changes = changes[0:-1*len(change_wrap)]+change_note+change_wrap\n",
    "            content = changes+content\n",
    "            update += 1\n",
    "            nb['cells'][start_cell]['source'] = content\n",
    "            nbformat.write(nb, to_file_path)\n",
    "            # stage file here\n",
    "            repo.git.add(str(to_file_path))\n",
    "        elif change_note in changes:\n",
    "            update += 0\n",
    "            \n",
    "    # markdown files\n",
    "    elif to_file_path.suffix == \".md\":\n",
    "        with open(to_file_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        # detect existing header in file\n",
    "        if content.startswith('<!--- header table --->') or content.startswith('![tracker](https://'):\n",
    "            end_str = '</table><br/><br/><br/><br/>\\n\\n'\n",
    "            end_index = content.index(end_str)+len(end_str)\n",
    "            header = content[0:end_index]\n",
    "            content = content[end_index:]\n",
    "        else:\n",
    "            print(f'Header is missing from: {to_file_path}')\n",
    "            header = ''\n",
    "            content = content\n",
    "        \n",
    "        # detect existing file change info - after header\n",
    "        if change_lead not in content:\n",
    "            changes = ''\n",
    "            content = content[content.index('#'):]\n",
    "        else:\n",
    "            changes = content[0:(content.index(change_wrap)+len(change_wrap))]\n",
    "            content = content[content.index('#'):]\n",
    "        \n",
    "        # edit/update change info\n",
    "        if change_lead not in changes and len(changes) < 1:\n",
    "            changes = change_lead+change_note+change_wrap\n",
    "            content = header+changes+content\n",
    "            update += 1\n",
    "            with open(to_file_path, 'w') as f:\n",
    "                f.write(content)\n",
    "            # stage file here\n",
    "            repo.git.add(str(to_file_path))\n",
    "        elif change_note not in changes:\n",
    "            changes = changes[0:-1*len(change_wrap)]+change_note+change_wrap\n",
    "            content = header+changes+content\n",
    "            update += 1\n",
    "            with open(to_file_path, 'w') as f:\n",
    "                f.write(content)\n",
    "            # stage file here\n",
    "            repo.git.add(str(to_file_path))\n",
    "        elif change_note in changes:\n",
    "            update += 0        \n",
    "            \n",
    "    else:\n",
    "        print(f'No changes made to: {to_file_path}')\n",
    "\n",
    "# commit here if update > 0 (staged above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "63413d25-8275-4b8f-99ac-8772e333a3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files), update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ece0ee54-618a-4a54-a8a1-0d4b10da5eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if staged changes then commit them\n",
    "if update > 0 and repo.index.diff(\"HEAD\"):\n",
    "    repo.index.commit(\"Added banner to files indicate moved location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939feb0e-c3cc-4258-8773-23d45df11b48",
   "metadata": {},
   "source": [
    "---\n",
    "## Check and Update references to the moved file\n",
    "\n",
    "Now that the file is moved any references to it will need to be updated.  This code will review all files in the repository for references to the `from_file_path` and update them to the `to_file_path`.  This includes relative links.  All the changed files will then be staged+commit.\n",
    "\n",
    "- list files\n",
    "- loop through files:\n",
    "    - read contents\n",
    "    - find relative links\n",
    "    - create absolute link\n",
    "    - see if absolute link in list of from files\n",
    "    - create new link to to_files\n",
    "    - replace link in file\n",
    "    - save file\n",
    "    - stage file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "955bf176-4a59-4e6b-8472-84e3d4dac920",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/Vertex AI Search/Vertex AI Search Python Client Overview.ipynb'),\n",
       "  PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search/Vertex AI Search Python Client Overview.ipynb')),\n",
       " (PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/Vertex AI Search/vertex_search_setup.md'),\n",
       "  PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search/vertex_search_setup.md')),\n",
       " (PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/Vertex AI Search/readme.md'),\n",
       "  PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search/readme.md'))]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files # a list of (from_file_path, to_file_path) tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d5aeacdf-8eb6-4185-84a8-3ad79c614834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a list of .md and .ipynb files from the full repository:\n",
    "matches = list(repo_path.rglob(\"*.md\")) + list(repo_path.rglob(\"*.ipynb\"))\n",
    "# filter out any that are in .ipynb_checkpoints directory or a known to_file_path (already edited above)\n",
    "matches = [\n",
    "    match_file_path\n",
    "    for match_file_path in matches\n",
    "    if match_file_path not in [to_file_path for _, to_file_path in files]\n",
    "    and '.ipynb_checkpoints' not in match_file_path.parts\n",
    "]\n",
    "#matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c270f-42ca-4a8a-bf03-949a7ef5ff93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbf546-311a-4020-b1a8-7657b0efc098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab4337-9f96-4546-b940-5ab5fd53baa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e27465-553c-41fd-a6bf-15218dc91890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d8bf6-c46d-4176-8446-a1603ba91916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb865bf-e98b-4dd6-b3fa-2c428e624239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a79dc-4de3-47e6-a4db-109fc2e20e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48872ea9-a78a-4882-9813-ba63bb0e132a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "075f520b-c47b-4d7d-aa19-7db916e6ace3",
   "metadata": {},
   "source": [
    "---\n",
    "## Some Checks Using `relative_links`\n",
    "\n",
    "(from_file_path, to_file_path, link, new_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e90ac66-d937-4842-a04e-424ad4f8ae2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/Vertex AI Search/Vertex AI Search Python Client Overview.ipynb'),\n",
       " PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search/Vertex AI Search Python Client Overview.ipynb'),\n",
       " './vertex_search_setup.md',\n",
       " './vertex_search_setup.md')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62d65d25-de0b-4f5a-84a2-c2f241e81792",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/Vertex AI Search/readme.md'),\n",
       " PosixPath('/home/jupyter/vertex-ai-mlops/Applied GenAI/legacy/Vertex AI Search/readme.md'),\n",
       " './Vertex%20AI%20Search%20Python%20Client%20Overview.ipynb',\n",
       " './Vertex%20AI%20Search%20Python%20Client%20Overview.ipynb')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_links[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1cd6e59-fad9-459f-b588-7b8c2b937a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relative_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df4ecff0-5f72-4f99-a6d6-ba299de001cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./vertex_search_setup.md False\n",
      "./vertex_search_setup.md False\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_0.png True\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_1.png True\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_2.png True\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_3.png True\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_4.png True\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_5.png True\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_6.png True\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_7.png True\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_8.png True\n",
      "../../../architectures/notebooks/applied/genai/vertex_ai_search/vertex_search_step_9.png True\n",
      "./vertex_search_setup.md False\n",
      "./Vertex%20AI%20Search%20Python%20Client%20Overview.ipynb False\n"
     ]
    }
   ],
   "source": [
    "for rl in relative_links:\n",
    "    print(rl[3], rl[3]!=rl[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a4ee3-df59-46d7-a0c6-d4089de55c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f6d5a-8446-4f49-8c50-b052078959e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
